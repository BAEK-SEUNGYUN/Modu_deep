{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modu_sonar_k-fold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wB6sjAz4dJF7sphjoIajq3sjpRIPUTza",
      "authorship_tag": "ABX9TyNyhIW8RjqaaiMd7QAb0CTt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BAEK-SEUNGYUN/modu_deep/blob/main/modu_sonar_k_fold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8SzMf8zvolv"
      },
      "source": [
        "# k-fold (k겹 교차 검증)\n",
        "딥러닝, 머신러닝 작업을 할 떄 알고리즘을 충분히 테스트하였어도 데이터가 충분치 않으면 좋은 결과를 내기가 어렵다.\n",
        "\n",
        "k-fold 란 데이터셋을 여러개로 나누어 하나씩 테스트셋으로 사용하고 나머지를 모두 합해서 학습셋으로 사용하는 방법\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc7SHfLpw-y9"
      },
      "source": [
        "###사용이유\n",
        "- 총 데이터 갯수가 적은 데이터 셋에 대하여 정확도를 향상시킬수 있음\n",
        "- 이는 기존에 Training/Validation/Test 세 개의 집단으로 분류하는 것보다, Training과 Test로만 분류할 때 학습 데이터 셋이 더 많기 때문\n",
        "- 데이터 수가 적은데 검증과 테스트에 데이터를 더 뺏기면 underfitting 등 성능이 미달되는 모델이 학습됨\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jm7V5j3w_Qf"
      },
      "source": [
        "from keras.models import Sequential   \n",
        "from keras.layers.core import Dense\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# 데이터를 원하는 숫자만큼 쪼개 각각 학습셋과 테스트셋으로 사용되게 만드는 함수\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQeJlUAxL-6"
      },
      "source": [
        "# seed 값 설정\n",
        "seed = 0\n",
        "numpy.random.seed(seed)\n",
        "tf.random.set_seed(3)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuacAGpdxNew"
      },
      "source": [
        "# sonar 데이터 가져오기\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset/sonar.csv')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "aOIMmxsayKnG",
        "outputId": "594b7904-6996-442c-b251-9d7276bdc449"
      },
      "source": [
        "# 데이터 확인\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0200</th>\n",
              "      <th>0.0371</th>\n",
              "      <th>0.0428</th>\n",
              "      <th>0.0207</th>\n",
              "      <th>0.0954</th>\n",
              "      <th>0.0986</th>\n",
              "      <th>0.1539</th>\n",
              "      <th>0.1601</th>\n",
              "      <th>0.3109</th>\n",
              "      <th>0.2111</th>\n",
              "      <th>0.1609</th>\n",
              "      <th>0.1582</th>\n",
              "      <th>0.2238</th>\n",
              "      <th>0.0645</th>\n",
              "      <th>0.0660</th>\n",
              "      <th>0.2273</th>\n",
              "      <th>0.3100</th>\n",
              "      <th>0.2999</th>\n",
              "      <th>0.5078</th>\n",
              "      <th>0.4797</th>\n",
              "      <th>0.5783</th>\n",
              "      <th>0.5071</th>\n",
              "      <th>0.4328</th>\n",
              "      <th>0.5550</th>\n",
              "      <th>0.6711</th>\n",
              "      <th>0.6415</th>\n",
              "      <th>0.7104</th>\n",
              "      <th>0.8080</th>\n",
              "      <th>0.6791</th>\n",
              "      <th>0.3857</th>\n",
              "      <th>0.1307</th>\n",
              "      <th>0.2604</th>\n",
              "      <th>0.5121</th>\n",
              "      <th>0.7547</th>\n",
              "      <th>0.8537</th>\n",
              "      <th>0.8507</th>\n",
              "      <th>0.6692</th>\n",
              "      <th>0.6097</th>\n",
              "      <th>0.4943</th>\n",
              "      <th>0.2744</th>\n",
              "      <th>0.0510</th>\n",
              "      <th>0.2834</th>\n",
              "      <th>0.2825</th>\n",
              "      <th>0.4256</th>\n",
              "      <th>0.2641</th>\n",
              "      <th>0.1386</th>\n",
              "      <th>0.1051</th>\n",
              "      <th>0.1343</th>\n",
              "      <th>0.0383</th>\n",
              "      <th>0.0324</th>\n",
              "      <th>0.0232</th>\n",
              "      <th>0.0027</th>\n",
              "      <th>0.0065</th>\n",
              "      <th>0.0159</th>\n",
              "      <th>0.0072</th>\n",
              "      <th>0.0167</th>\n",
              "      <th>0.0180</th>\n",
              "      <th>0.0084</th>\n",
              "      <th>0.0090</th>\n",
              "      <th>0.0032</th>\n",
              "      <th>R</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0523</td>\n",
              "      <td>0.0843</td>\n",
              "      <td>0.0689</td>\n",
              "      <td>0.1183</td>\n",
              "      <td>0.2583</td>\n",
              "      <td>0.2156</td>\n",
              "      <td>0.3481</td>\n",
              "      <td>0.3337</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.4918</td>\n",
              "      <td>0.6552</td>\n",
              "      <td>0.6919</td>\n",
              "      <td>0.7797</td>\n",
              "      <td>0.7464</td>\n",
              "      <td>0.9444</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8874</td>\n",
              "      <td>0.8024</td>\n",
              "      <td>0.7818</td>\n",
              "      <td>0.5212</td>\n",
              "      <td>0.4052</td>\n",
              "      <td>0.3957</td>\n",
              "      <td>0.3914</td>\n",
              "      <td>0.3250</td>\n",
              "      <td>0.3200</td>\n",
              "      <td>0.3271</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>0.2028</td>\n",
              "      <td>0.3788</td>\n",
              "      <td>0.2947</td>\n",
              "      <td>0.1984</td>\n",
              "      <td>0.2341</td>\n",
              "      <td>0.1306</td>\n",
              "      <td>0.4182</td>\n",
              "      <td>0.3835</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.1840</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.1674</td>\n",
              "      <td>0.0583</td>\n",
              "      <td>0.1401</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.0621</td>\n",
              "      <td>0.0203</td>\n",
              "      <td>0.0530</td>\n",
              "      <td>0.0742</td>\n",
              "      <td>0.0409</td>\n",
              "      <td>0.0061</td>\n",
              "      <td>0.0125</td>\n",
              "      <td>0.0084</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>0.0191</td>\n",
              "      <td>0.0140</td>\n",
              "      <td>0.0049</td>\n",
              "      <td>0.0052</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0262</td>\n",
              "      <td>0.0582</td>\n",
              "      <td>0.1099</td>\n",
              "      <td>0.1083</td>\n",
              "      <td>0.0974</td>\n",
              "      <td>0.2280</td>\n",
              "      <td>0.2431</td>\n",
              "      <td>0.3771</td>\n",
              "      <td>0.5598</td>\n",
              "      <td>0.6194</td>\n",
              "      <td>0.6333</td>\n",
              "      <td>0.7060</td>\n",
              "      <td>0.5544</td>\n",
              "      <td>0.5320</td>\n",
              "      <td>0.6479</td>\n",
              "      <td>0.6931</td>\n",
              "      <td>0.6759</td>\n",
              "      <td>0.7551</td>\n",
              "      <td>0.8929</td>\n",
              "      <td>0.8619</td>\n",
              "      <td>0.7974</td>\n",
              "      <td>0.6737</td>\n",
              "      <td>0.4293</td>\n",
              "      <td>0.3648</td>\n",
              "      <td>0.5331</td>\n",
              "      <td>0.2413</td>\n",
              "      <td>0.5070</td>\n",
              "      <td>0.8533</td>\n",
              "      <td>0.6036</td>\n",
              "      <td>0.8514</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.5045</td>\n",
              "      <td>0.1862</td>\n",
              "      <td>0.2709</td>\n",
              "      <td>0.4232</td>\n",
              "      <td>0.3043</td>\n",
              "      <td>0.6116</td>\n",
              "      <td>0.6756</td>\n",
              "      <td>0.5375</td>\n",
              "      <td>0.4719</td>\n",
              "      <td>0.4647</td>\n",
              "      <td>0.2587</td>\n",
              "      <td>0.2129</td>\n",
              "      <td>0.2222</td>\n",
              "      <td>0.2111</td>\n",
              "      <td>0.0176</td>\n",
              "      <td>0.1348</td>\n",
              "      <td>0.0744</td>\n",
              "      <td>0.0130</td>\n",
              "      <td>0.0106</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.0232</td>\n",
              "      <td>0.0166</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0180</td>\n",
              "      <td>0.0244</td>\n",
              "      <td>0.0316</td>\n",
              "      <td>0.0164</td>\n",
              "      <td>0.0095</td>\n",
              "      <td>0.0078</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0100</td>\n",
              "      <td>0.0171</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0205</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.1098</td>\n",
              "      <td>0.1276</td>\n",
              "      <td>0.0598</td>\n",
              "      <td>0.1264</td>\n",
              "      <td>0.0881</td>\n",
              "      <td>0.1992</td>\n",
              "      <td>0.0184</td>\n",
              "      <td>0.2261</td>\n",
              "      <td>0.1729</td>\n",
              "      <td>0.2131</td>\n",
              "      <td>0.0693</td>\n",
              "      <td>0.2281</td>\n",
              "      <td>0.4060</td>\n",
              "      <td>0.3973</td>\n",
              "      <td>0.2741</td>\n",
              "      <td>0.3690</td>\n",
              "      <td>0.5556</td>\n",
              "      <td>0.4846</td>\n",
              "      <td>0.3140</td>\n",
              "      <td>0.5334</td>\n",
              "      <td>0.5256</td>\n",
              "      <td>0.2520</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.3559</td>\n",
              "      <td>0.6260</td>\n",
              "      <td>0.7340</td>\n",
              "      <td>0.6120</td>\n",
              "      <td>0.3497</td>\n",
              "      <td>0.3953</td>\n",
              "      <td>0.3012</td>\n",
              "      <td>0.5408</td>\n",
              "      <td>0.8814</td>\n",
              "      <td>0.9857</td>\n",
              "      <td>0.9167</td>\n",
              "      <td>0.6121</td>\n",
              "      <td>0.5006</td>\n",
              "      <td>0.3210</td>\n",
              "      <td>0.3202</td>\n",
              "      <td>0.4295</td>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.2655</td>\n",
              "      <td>0.1576</td>\n",
              "      <td>0.0681</td>\n",
              "      <td>0.0294</td>\n",
              "      <td>0.0241</td>\n",
              "      <td>0.0121</td>\n",
              "      <td>0.0036</td>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0073</td>\n",
              "      <td>0.0050</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0040</td>\n",
              "      <td>0.0117</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0762</td>\n",
              "      <td>0.0666</td>\n",
              "      <td>0.0481</td>\n",
              "      <td>0.0394</td>\n",
              "      <td>0.0590</td>\n",
              "      <td>0.0649</td>\n",
              "      <td>0.1209</td>\n",
              "      <td>0.2467</td>\n",
              "      <td>0.3564</td>\n",
              "      <td>0.4459</td>\n",
              "      <td>0.4152</td>\n",
              "      <td>0.3952</td>\n",
              "      <td>0.4256</td>\n",
              "      <td>0.4135</td>\n",
              "      <td>0.4528</td>\n",
              "      <td>0.5326</td>\n",
              "      <td>0.7306</td>\n",
              "      <td>0.6193</td>\n",
              "      <td>0.2032</td>\n",
              "      <td>0.4636</td>\n",
              "      <td>0.4148</td>\n",
              "      <td>0.4292</td>\n",
              "      <td>0.5730</td>\n",
              "      <td>0.5399</td>\n",
              "      <td>0.3161</td>\n",
              "      <td>0.2285</td>\n",
              "      <td>0.6995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.4724</td>\n",
              "      <td>0.5103</td>\n",
              "      <td>0.5459</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>0.0981</td>\n",
              "      <td>0.1951</td>\n",
              "      <td>0.4181</td>\n",
              "      <td>0.4604</td>\n",
              "      <td>0.3217</td>\n",
              "      <td>0.2828</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.1979</td>\n",
              "      <td>0.2444</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.0841</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>0.0357</td>\n",
              "      <td>0.0085</td>\n",
              "      <td>0.0230</td>\n",
              "      <td>0.0046</td>\n",
              "      <td>0.0156</td>\n",
              "      <td>0.0031</td>\n",
              "      <td>0.0054</td>\n",
              "      <td>0.0105</td>\n",
              "      <td>0.0110</td>\n",
              "      <td>0.0015</td>\n",
              "      <td>0.0072</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0107</td>\n",
              "      <td>0.0094</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0286</td>\n",
              "      <td>0.0453</td>\n",
              "      <td>0.0277</td>\n",
              "      <td>0.0174</td>\n",
              "      <td>0.0384</td>\n",
              "      <td>0.0990</td>\n",
              "      <td>0.1201</td>\n",
              "      <td>0.1833</td>\n",
              "      <td>0.2105</td>\n",
              "      <td>0.3039</td>\n",
              "      <td>0.2988</td>\n",
              "      <td>0.4250</td>\n",
              "      <td>0.6343</td>\n",
              "      <td>0.8198</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.9508</td>\n",
              "      <td>0.9025</td>\n",
              "      <td>0.7234</td>\n",
              "      <td>0.5122</td>\n",
              "      <td>0.2074</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.5890</td>\n",
              "      <td>0.2872</td>\n",
              "      <td>0.2043</td>\n",
              "      <td>0.5782</td>\n",
              "      <td>0.5389</td>\n",
              "      <td>0.3750</td>\n",
              "      <td>0.3411</td>\n",
              "      <td>0.5067</td>\n",
              "      <td>0.5580</td>\n",
              "      <td>0.4778</td>\n",
              "      <td>0.3299</td>\n",
              "      <td>0.2198</td>\n",
              "      <td>0.1407</td>\n",
              "      <td>0.2856</td>\n",
              "      <td>0.3807</td>\n",
              "      <td>0.4158</td>\n",
              "      <td>0.4054</td>\n",
              "      <td>0.3296</td>\n",
              "      <td>0.2707</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.0723</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1192</td>\n",
              "      <td>0.1089</td>\n",
              "      <td>0.0623</td>\n",
              "      <td>0.0494</td>\n",
              "      <td>0.0264</td>\n",
              "      <td>0.0081</td>\n",
              "      <td>0.0104</td>\n",
              "      <td>0.0045</td>\n",
              "      <td>0.0014</td>\n",
              "      <td>0.0038</td>\n",
              "      <td>0.0013</td>\n",
              "      <td>0.0089</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.0051</td>\n",
              "      <td>0.0062</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0.0200  0.0371  0.0428  0.0207  0.0954  ...  0.0180  0.0084  0.0090  0.0032  R\n",
              "0  0.0453  0.0523  0.0843  0.0689  0.1183  ...  0.0140  0.0049  0.0052  0.0044  R\n",
              "1  0.0262  0.0582  0.1099  0.1083  0.0974  ...  0.0316  0.0164  0.0095  0.0078  R\n",
              "2  0.0100  0.0171  0.0623  0.0205  0.0205  ...  0.0050  0.0044  0.0040  0.0117  R\n",
              "3  0.0762  0.0666  0.0481  0.0394  0.0590  ...  0.0072  0.0048  0.0107  0.0094  R\n",
              "4  0.0286  0.0453  0.0277  0.0174  0.0384  ...  0.0057  0.0027  0.0051  0.0062  R\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiHiDogjyO2X",
        "outputId": "f13863f0-d909-4541-d95e-2f13139aff1a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 207 entries, 0 to 206\n",
            "Data columns (total 61 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0.0200  207 non-null    float64\n",
            " 1   0.0371  207 non-null    float64\n",
            " 2   0.0428  207 non-null    float64\n",
            " 3   0.0207  207 non-null    float64\n",
            " 4   0.0954  207 non-null    float64\n",
            " 5   0.0986  207 non-null    float64\n",
            " 6   0.1539  207 non-null    float64\n",
            " 7   0.1601  207 non-null    float64\n",
            " 8   0.3109  207 non-null    float64\n",
            " 9   0.2111  207 non-null    float64\n",
            " 10  0.1609  207 non-null    float64\n",
            " 11  0.1582  207 non-null    float64\n",
            " 12  0.2238  207 non-null    float64\n",
            " 13  0.0645  207 non-null    float64\n",
            " 14  0.0660  207 non-null    float64\n",
            " 15  0.2273  207 non-null    float64\n",
            " 16  0.3100  207 non-null    float64\n",
            " 17  0.2999  207 non-null    float64\n",
            " 18  0.5078  207 non-null    float64\n",
            " 19  0.4797  207 non-null    float64\n",
            " 20  0.5783  207 non-null    float64\n",
            " 21  0.5071  207 non-null    float64\n",
            " 22  0.4328  207 non-null    float64\n",
            " 23  0.5550  207 non-null    float64\n",
            " 24  0.6711  207 non-null    float64\n",
            " 25  0.6415  207 non-null    float64\n",
            " 26  0.7104  207 non-null    float64\n",
            " 27  0.8080  207 non-null    float64\n",
            " 28  0.6791  207 non-null    float64\n",
            " 29  0.3857  207 non-null    float64\n",
            " 30  0.1307  207 non-null    float64\n",
            " 31  0.2604  207 non-null    float64\n",
            " 32  0.5121  207 non-null    float64\n",
            " 33  0.7547  207 non-null    float64\n",
            " 34  0.8537  207 non-null    float64\n",
            " 35  0.8507  207 non-null    float64\n",
            " 36  0.6692  207 non-null    float64\n",
            " 37  0.6097  207 non-null    float64\n",
            " 38  0.4943  207 non-null    float64\n",
            " 39  0.2744  207 non-null    float64\n",
            " 40  0.0510  207 non-null    float64\n",
            " 41  0.2834  207 non-null    float64\n",
            " 42  0.2825  207 non-null    float64\n",
            " 43  0.4256  207 non-null    float64\n",
            " 44  0.2641  207 non-null    float64\n",
            " 45  0.1386  207 non-null    float64\n",
            " 46  0.1051  207 non-null    float64\n",
            " 47  0.1343  207 non-null    float64\n",
            " 48  0.0383  207 non-null    float64\n",
            " 49  0.0324  207 non-null    float64\n",
            " 50  0.0232  207 non-null    float64\n",
            " 51  0.0027  207 non-null    float64\n",
            " 52  0.0065  207 non-null    float64\n",
            " 53  0.0159  207 non-null    float64\n",
            " 54  0.0072  207 non-null    float64\n",
            " 55  0.0167  207 non-null    float64\n",
            " 56  0.0180  207 non-null    float64\n",
            " 57  0.0084  207 non-null    float64\n",
            " 58  0.0090  207 non-null    float64\n",
            " 59  0.0032  207 non-null    float64\n",
            " 60  R       207 non-null    object \n",
            "dtypes: float64(60), object(1)\n",
            "memory usage: 98.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "KBIzaGUCyQJT",
        "outputId": "35535006-d0cc-4b9c-e9f3-74529424be9d"
      },
      "source": [
        "df.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0.0200</th>\n",
              "      <th>0.0371</th>\n",
              "      <th>0.0428</th>\n",
              "      <th>0.0207</th>\n",
              "      <th>0.0954</th>\n",
              "      <th>0.0986</th>\n",
              "      <th>0.1539</th>\n",
              "      <th>0.1601</th>\n",
              "      <th>0.3109</th>\n",
              "      <th>0.2111</th>\n",
              "      <th>0.1609</th>\n",
              "      <th>0.1582</th>\n",
              "      <th>0.2238</th>\n",
              "      <th>0.0645</th>\n",
              "      <th>0.0660</th>\n",
              "      <th>0.2273</th>\n",
              "      <th>0.3100</th>\n",
              "      <th>0.2999</th>\n",
              "      <th>0.5078</th>\n",
              "      <th>0.4797</th>\n",
              "      <th>0.5783</th>\n",
              "      <th>0.5071</th>\n",
              "      <th>0.4328</th>\n",
              "      <th>0.5550</th>\n",
              "      <th>0.6711</th>\n",
              "      <th>0.6415</th>\n",
              "      <th>0.7104</th>\n",
              "      <th>0.8080</th>\n",
              "      <th>0.6791</th>\n",
              "      <th>0.3857</th>\n",
              "      <th>0.1307</th>\n",
              "      <th>0.2604</th>\n",
              "      <th>0.5121</th>\n",
              "      <th>0.7547</th>\n",
              "      <th>0.8537</th>\n",
              "      <th>0.8507</th>\n",
              "      <th>0.6692</th>\n",
              "      <th>0.6097</th>\n",
              "      <th>0.4943</th>\n",
              "      <th>0.2744</th>\n",
              "      <th>0.0510</th>\n",
              "      <th>0.2834</th>\n",
              "      <th>0.2825</th>\n",
              "      <th>0.4256</th>\n",
              "      <th>0.2641</th>\n",
              "      <th>0.1386</th>\n",
              "      <th>0.1051</th>\n",
              "      <th>0.1343</th>\n",
              "      <th>0.0383</th>\n",
              "      <th>0.0324</th>\n",
              "      <th>0.0232</th>\n",
              "      <th>0.0027</th>\n",
              "      <th>0.0065</th>\n",
              "      <th>0.0159</th>\n",
              "      <th>0.0072</th>\n",
              "      <th>0.0167</th>\n",
              "      <th>0.0180</th>\n",
              "      <th>0.0084</th>\n",
              "      <th>0.0090</th>\n",
              "      <th>0.0032</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "      <td>207.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.029208</td>\n",
              "      <td>0.038443</td>\n",
              "      <td>0.043837</td>\n",
              "      <td>0.054053</td>\n",
              "      <td>0.075105</td>\n",
              "      <td>0.104599</td>\n",
              "      <td>0.121591</td>\n",
              "      <td>0.134677</td>\n",
              "      <td>0.177361</td>\n",
              "      <td>0.208245</td>\n",
              "      <td>0.236376</td>\n",
              "      <td>0.250666</td>\n",
              "      <td>0.273544</td>\n",
              "      <td>0.297689</td>\n",
              "      <td>0.321429</td>\n",
              "      <td>0.379217</td>\n",
              "      <td>0.416495</td>\n",
              "      <td>0.453055</td>\n",
              "      <td>0.504797</td>\n",
              "      <td>0.563449</td>\n",
              "      <td>0.609209</td>\n",
              "      <td>0.624841</td>\n",
              "      <td>0.648010</td>\n",
              "      <td>0.673223</td>\n",
              "      <td>0.675444</td>\n",
              "      <td>0.700148</td>\n",
              "      <td>0.702115</td>\n",
              "      <td>0.693473</td>\n",
              "      <td>0.641895</td>\n",
              "      <td>0.581871</td>\n",
              "      <td>0.506281</td>\n",
              "      <td>0.439903</td>\n",
              "      <td>0.416761</td>\n",
              "      <td>0.401535</td>\n",
              "      <td>0.390343</td>\n",
              "      <td>0.382597</td>\n",
              "      <td>0.362331</td>\n",
              "      <td>0.338353</td>\n",
              "      <td>0.324986</td>\n",
              "      <td>0.311385</td>\n",
              "      <td>0.290403</td>\n",
              "      <td>0.278269</td>\n",
              "      <td>0.246368</td>\n",
              "      <td>0.213053</td>\n",
              "      <td>0.196909</td>\n",
              "      <td>0.160738</td>\n",
              "      <td>0.122537</td>\n",
              "      <td>0.091217</td>\n",
              "      <td>0.051995</td>\n",
              "      <td>0.020366</td>\n",
              "      <td>0.016034</td>\n",
              "      <td>0.013472</td>\n",
              "      <td>0.010729</td>\n",
              "      <td>0.010917</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.008181</td>\n",
              "      <td>0.007771</td>\n",
              "      <td>0.007947</td>\n",
              "      <td>0.007936</td>\n",
              "      <td>0.006523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.023038</td>\n",
              "      <td>0.033040</td>\n",
              "      <td>0.038521</td>\n",
              "      <td>0.046583</td>\n",
              "      <td>0.055669</td>\n",
              "      <td>0.059247</td>\n",
              "      <td>0.061897</td>\n",
              "      <td>0.085340</td>\n",
              "      <td>0.118311</td>\n",
              "      <td>0.134741</td>\n",
              "      <td>0.132923</td>\n",
              "      <td>0.140264</td>\n",
              "      <td>0.141262</td>\n",
              "      <td>0.164075</td>\n",
              "      <td>0.205158</td>\n",
              "      <td>0.232975</td>\n",
              "      <td>0.264213</td>\n",
              "      <td>0.261947</td>\n",
              "      <td>0.258614</td>\n",
              "      <td>0.263225</td>\n",
              "      <td>0.258434</td>\n",
              "      <td>0.256373</td>\n",
              "      <td>0.250335</td>\n",
              "      <td>0.239555</td>\n",
              "      <td>0.245520</td>\n",
              "      <td>0.237768</td>\n",
              "      <td>0.246252</td>\n",
              "      <td>0.237631</td>\n",
              "      <td>0.240818</td>\n",
              "      <td>0.220864</td>\n",
              "      <td>0.212917</td>\n",
              "      <td>0.213389</td>\n",
              "      <td>0.206907</td>\n",
              "      <td>0.230499</td>\n",
              "      <td>0.257756</td>\n",
              "      <td>0.262755</td>\n",
              "      <td>0.239546</td>\n",
              "      <td>0.212655</td>\n",
              "      <td>0.199210</td>\n",
              "      <td>0.179076</td>\n",
              "      <td>0.170717</td>\n",
              "      <td>0.169137</td>\n",
              "      <td>0.139308</td>\n",
              "      <td>0.132795</td>\n",
              "      <td>0.151924</td>\n",
              "      <td>0.134254</td>\n",
              "      <td>0.087155</td>\n",
              "      <td>0.062496</td>\n",
              "      <td>0.036029</td>\n",
              "      <td>0.013673</td>\n",
              "      <td>0.012027</td>\n",
              "      <td>0.009628</td>\n",
              "      <td>0.007071</td>\n",
              "      <td>0.007310</td>\n",
              "      <td>0.007103</td>\n",
              "      <td>0.005719</td>\n",
              "      <td>0.005756</td>\n",
              "      <td>0.006485</td>\n",
              "      <td>0.006196</td>\n",
              "      <td>0.005038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.001500</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006700</td>\n",
              "      <td>0.010200</td>\n",
              "      <td>0.003300</td>\n",
              "      <td>0.005500</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.011300</td>\n",
              "      <td>0.028900</td>\n",
              "      <td>0.023600</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.027300</td>\n",
              "      <td>0.003100</td>\n",
              "      <td>0.016200</td>\n",
              "      <td>0.034900</td>\n",
              "      <td>0.037500</td>\n",
              "      <td>0.049400</td>\n",
              "      <td>0.065600</td>\n",
              "      <td>0.051200</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>0.056300</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.024000</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.048100</td>\n",
              "      <td>0.028400</td>\n",
              "      <td>0.014400</td>\n",
              "      <td>0.061300</td>\n",
              "      <td>0.048200</td>\n",
              "      <td>0.040400</td>\n",
              "      <td>0.047700</td>\n",
              "      <td>0.021200</td>\n",
              "      <td>0.022300</td>\n",
              "      <td>0.008000</td>\n",
              "      <td>0.035100</td>\n",
              "      <td>0.038300</td>\n",
              "      <td>0.037100</td>\n",
              "      <td>0.011700</td>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.001000</td>\n",
              "      <td>0.000600</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000300</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.013300</td>\n",
              "      <td>0.016400</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.024450</td>\n",
              "      <td>0.037700</td>\n",
              "      <td>0.066950</td>\n",
              "      <td>0.080600</td>\n",
              "      <td>0.080350</td>\n",
              "      <td>0.096750</td>\n",
              "      <td>0.111150</td>\n",
              "      <td>0.128200</td>\n",
              "      <td>0.133450</td>\n",
              "      <td>0.165750</td>\n",
              "      <td>0.176100</td>\n",
              "      <td>0.166500</td>\n",
              "      <td>0.195900</td>\n",
              "      <td>0.205500</td>\n",
              "      <td>0.241950</td>\n",
              "      <td>0.299050</td>\n",
              "      <td>0.350450</td>\n",
              "      <td>0.397550</td>\n",
              "      <td>0.406350</td>\n",
              "      <td>0.455250</td>\n",
              "      <td>0.540450</td>\n",
              "      <td>0.524800</td>\n",
              "      <td>0.543550</td>\n",
              "      <td>0.529800</td>\n",
              "      <td>0.533950</td>\n",
              "      <td>0.461300</td>\n",
              "      <td>0.414250</td>\n",
              "      <td>0.349300</td>\n",
              "      <td>0.284100</td>\n",
              "      <td>0.257350</td>\n",
              "      <td>0.217550</td>\n",
              "      <td>0.178550</td>\n",
              "      <td>0.154000</td>\n",
              "      <td>0.160000</td>\n",
              "      <td>0.174250</td>\n",
              "      <td>0.172450</td>\n",
              "      <td>0.185900</td>\n",
              "      <td>0.164100</td>\n",
              "      <td>0.158700</td>\n",
              "      <td>0.155200</td>\n",
              "      <td>0.126850</td>\n",
              "      <td>0.094450</td>\n",
              "      <td>0.068400</td>\n",
              "      <td>0.064200</td>\n",
              "      <td>0.044950</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.008350</td>\n",
              "      <td>0.007350</td>\n",
              "      <td>0.005050</td>\n",
              "      <td>0.005350</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>0.004400</td>\n",
              "      <td>0.003700</td>\n",
              "      <td>0.003600</td>\n",
              "      <td>0.003650</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.022800</td>\n",
              "      <td>0.030800</td>\n",
              "      <td>0.034200</td>\n",
              "      <td>0.044100</td>\n",
              "      <td>0.062000</td>\n",
              "      <td>0.092100</td>\n",
              "      <td>0.105600</td>\n",
              "      <td>0.111900</td>\n",
              "      <td>0.152200</td>\n",
              "      <td>0.181000</td>\n",
              "      <td>0.225100</td>\n",
              "      <td>0.249700</td>\n",
              "      <td>0.265500</td>\n",
              "      <td>0.281900</td>\n",
              "      <td>0.284000</td>\n",
              "      <td>0.307500</td>\n",
              "      <td>0.306800</td>\n",
              "      <td>0.370900</td>\n",
              "      <td>0.434800</td>\n",
              "      <td>0.543000</td>\n",
              "      <td>0.627500</td>\n",
              "      <td>0.667000</td>\n",
              "      <td>0.700700</td>\n",
              "      <td>0.701200</td>\n",
              "      <td>0.722100</td>\n",
              "      <td>0.754500</td>\n",
              "      <td>0.753900</td>\n",
              "      <td>0.731700</td>\n",
              "      <td>0.682500</td>\n",
              "      <td>0.607400</td>\n",
              "      <td>0.490600</td>\n",
              "      <td>0.430300</td>\n",
              "      <td>0.390300</td>\n",
              "      <td>0.349700</td>\n",
              "      <td>0.310800</td>\n",
              "      <td>0.319500</td>\n",
              "      <td>0.303900</td>\n",
              "      <td>0.310400</td>\n",
              "      <td>0.282900</td>\n",
              "      <td>0.279000</td>\n",
              "      <td>0.260500</td>\n",
              "      <td>0.244400</td>\n",
              "      <td>0.221100</td>\n",
              "      <td>0.177600</td>\n",
              "      <td>0.147300</td>\n",
              "      <td>0.121100</td>\n",
              "      <td>0.101500</td>\n",
              "      <td>0.077700</td>\n",
              "      <td>0.044900</td>\n",
              "      <td>0.017900</td>\n",
              "      <td>0.013800</td>\n",
              "      <td>0.011500</td>\n",
              "      <td>0.009600</td>\n",
              "      <td>0.009300</td>\n",
              "      <td>0.007500</td>\n",
              "      <td>0.006800</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.005800</td>\n",
              "      <td>0.006300</td>\n",
              "      <td>0.005300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.035800</td>\n",
              "      <td>0.048100</td>\n",
              "      <td>0.058200</td>\n",
              "      <td>0.065700</td>\n",
              "      <td>0.101050</td>\n",
              "      <td>0.134150</td>\n",
              "      <td>0.153050</td>\n",
              "      <td>0.169800</td>\n",
              "      <td>0.231500</td>\n",
              "      <td>0.269000</td>\n",
              "      <td>0.301800</td>\n",
              "      <td>0.331600</td>\n",
              "      <td>0.351500</td>\n",
              "      <td>0.386950</td>\n",
              "      <td>0.453050</td>\n",
              "      <td>0.536050</td>\n",
              "      <td>0.660050</td>\n",
              "      <td>0.679100</td>\n",
              "      <td>0.731900</td>\n",
              "      <td>0.809450</td>\n",
              "      <td>0.818050</td>\n",
              "      <td>0.832150</td>\n",
              "      <td>0.852250</td>\n",
              "      <td>0.873350</td>\n",
              "      <td>0.874550</td>\n",
              "      <td>0.893800</td>\n",
              "      <td>0.917400</td>\n",
              "      <td>0.901850</td>\n",
              "      <td>0.852350</td>\n",
              "      <td>0.736950</td>\n",
              "      <td>0.643200</td>\n",
              "      <td>0.585700</td>\n",
              "      <td>0.556750</td>\n",
              "      <td>0.584400</td>\n",
              "      <td>0.591400</td>\n",
              "      <td>0.553950</td>\n",
              "      <td>0.510200</td>\n",
              "      <td>0.438750</td>\n",
              "      <td>0.430550</td>\n",
              "      <td>0.424700</td>\n",
              "      <td>0.389150</td>\n",
              "      <td>0.385100</td>\n",
              "      <td>0.325050</td>\n",
              "      <td>0.267650</td>\n",
              "      <td>0.229750</td>\n",
              "      <td>0.200650</td>\n",
              "      <td>0.154750</td>\n",
              "      <td>0.119700</td>\n",
              "      <td>0.068950</td>\n",
              "      <td>0.025100</td>\n",
              "      <td>0.020700</td>\n",
              "      <td>0.016750</td>\n",
              "      <td>0.014900</td>\n",
              "      <td>0.014450</td>\n",
              "      <td>0.012100</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.010400</td>\n",
              "      <td>0.010350</td>\n",
              "      <td>0.008550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>0.137100</td>\n",
              "      <td>0.233900</td>\n",
              "      <td>0.305900</td>\n",
              "      <td>0.426400</td>\n",
              "      <td>0.401000</td>\n",
              "      <td>0.382300</td>\n",
              "      <td>0.372900</td>\n",
              "      <td>0.459000</td>\n",
              "      <td>0.682800</td>\n",
              "      <td>0.710600</td>\n",
              "      <td>0.734200</td>\n",
              "      <td>0.706000</td>\n",
              "      <td>0.713100</td>\n",
              "      <td>0.997000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.998800</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.965700</td>\n",
              "      <td>0.930600</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.964700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.949700</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.985700</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.899500</td>\n",
              "      <td>0.824600</td>\n",
              "      <td>0.773300</td>\n",
              "      <td>0.776200</td>\n",
              "      <td>0.703400</td>\n",
              "      <td>0.729200</td>\n",
              "      <td>0.552200</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.198100</td>\n",
              "      <td>0.082500</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>0.070900</td>\n",
              "      <td>0.039000</td>\n",
              "      <td>0.035200</td>\n",
              "      <td>0.044700</td>\n",
              "      <td>0.039400</td>\n",
              "      <td>0.035500</td>\n",
              "      <td>0.044000</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.043900</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           0.0200      0.0371      0.0428  ...      0.0084      0.0090      0.0032\n",
              "count  207.000000  207.000000  207.000000  ...  207.000000  207.000000  207.000000\n",
              "mean     0.029208    0.038443    0.043837  ...    0.007947    0.007936    0.006523\n",
              "std      0.023038    0.033040    0.038521  ...    0.006485    0.006196    0.005038\n",
              "min      0.001500    0.000600    0.001500  ...    0.000300    0.000100    0.000600\n",
              "25%      0.013300    0.016400    0.018900  ...    0.003600    0.003650    0.003100\n",
              "50%      0.022800    0.030800    0.034200  ...    0.005800    0.006300    0.005300\n",
              "75%      0.035800    0.048100    0.058200  ...    0.010400    0.010350    0.008550\n",
              "max      0.137100    0.233900    0.305900  ...    0.044000    0.036400    0.043900\n",
              "\n",
              "[8 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZscjRprySgg",
        "outputId": "3fd199ee-37c6-463e-a186-41548a32e7ee"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(207, 61)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gutyjNNyTRT",
        "outputId": "dd004ff9-1438-41ba-d1db-20a5306d1cda"
      },
      "source": [
        "print(df.values)\n",
        "\n",
        "dataset = df.values"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0453 0.0523 0.0843 ... 0.0052 0.0044 'R']\n",
            " [0.0262 0.0582 0.1099 ... 0.0095 0.0078 'R']\n",
            " [0.01 0.0171 0.0623 ... 0.004 0.0117 'R']\n",
            " ...\n",
            " [0.0522 0.0437 0.018 ... 0.0077 0.0031 'M']\n",
            " [0.0303 0.0353 0.049 ... 0.0036 0.0048 'M']\n",
            " [0.026 0.0363 0.0136 ... 0.0061 0.0115 'M']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbFwceMCyXkx",
        "outputId": "869618a8-81e2-4d1c-a313-8ee511b3b740"
      },
      "source": [
        "# X = dataset[:,:60]     이 코드를 아래 코드처럼 바꾸어주어야한다.\n",
        "# 그렇지 않으면 model.fit에서 ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type float).\n",
        "# 이런 에러가 발생\n",
        "X = dataset[:,:60].astype(float)\n",
        "Y_obj = dataset[:,60]\n",
        "print(X)\n",
        "\n",
        "\n",
        "# https://devbull.xyz/failed-to-convert-a-numpy-array-to-a-tensor-unsupported-object-type-float/\n",
        "#"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.0453 0.0523 0.0843 ... 0.0049 0.0052 0.0044]\n",
            " [0.0262 0.0582 0.1099 ... 0.0164 0.0095 0.0078]\n",
            " [0.01   0.0171 0.0623 ... 0.0044 0.004  0.0117]\n",
            " ...\n",
            " [0.0522 0.0437 0.018  ... 0.0138 0.0077 0.0031]\n",
            " [0.0303 0.0353 0.049  ... 0.0079 0.0036 0.0048]\n",
            " [0.026  0.0363 0.0136 ... 0.0036 0.0061 0.0115]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRx-frq-yj3q",
        "outputId": "6dc92951-8bd4-4fad-867a-948fa07ad6ad"
      },
      "source": [
        "print(Y_obj)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R' 'R'\n",
            " 'R' 'R' 'R' 'R' 'R' 'R' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
            " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywL6BVEryntI",
        "outputId": "45ef1bc5-5599-481c-9b51-5158ac9a7bbe"
      },
      "source": [
        "# 문자열 변환\n",
        "e = LabelEncoder()\n",
        "e.fit(Y_obj)\n",
        "Y = e.transform(Y_obj)\n",
        "print(Y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvWFSroYy7eK"
      },
      "source": [
        "# 데이터를 10개의 파일로 쪼갠다\n",
        "n_fold = 10\n",
        "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=seed)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V5BNHuKD0ecU",
        "outputId": "54b5a751-8906-4df7-84eb-fc336ba7bada"
      },
      "source": [
        "skf"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StratifiedKFold(n_splits=10, random_state=0, shuffle=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtUUzxyg0gkB"
      },
      "source": [
        "# 빈 accuracy 배열\n",
        "accuracy = []"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_7XR9o10l_n",
        "outputId": "12a5a0f3-18da-427a-c1dc-0a3e4036405e"
      },
      "source": [
        "# 모델의 설정, 컴파일, 실행\n",
        "for train, test in skf.split(X, Y):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(24, input_dim=60, activation='relu'))\n",
        "    model.add(Dense(10, activation='relu'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='mean_squared_error',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    model.fit(X[train], Y[train], epochs=100, batch_size=5)\n",
        "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
        "    accuracy.append(k_accuracy)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 13s 1ms/step - loss: 0.2779 - accuracy: 0.4425\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.5859\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2341 - accuracy: 0.6403\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2264 - accuracy: 0.6535\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2227 - accuracy: 0.7290\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2229 - accuracy: 0.6864\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2142 - accuracy: 0.7053\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1949 - accuracy: 0.8037\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1787 - accuracy: 0.7970\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1883 - accuracy: 0.7770\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1776 - accuracy: 0.8246\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1688 - accuracy: 0.7821\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1624 - accuracy: 0.7934\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1661 - accuracy: 0.7147\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.8433\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1256 - accuracy: 0.8615\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1361 - accuracy: 0.8018\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1482 - accuracy: 0.7779\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1435 - accuracy: 0.7846\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1232 - accuracy: 0.8318\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1247 - accuracy: 0.8205\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1183 - accuracy: 0.8625\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1192 - accuracy: 0.8723\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8563\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1159 - accuracy: 0.8351\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1106 - accuracy: 0.8486\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0976 - accuracy: 0.8823\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1066 - accuracy: 0.8423\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.8733\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.9101\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0957 - accuracy: 0.8527\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1121 - accuracy: 0.8417\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0980 - accuracy: 0.8691\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0802 - accuracy: 0.9034\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1124 - accuracy: 0.8202\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0991 - accuracy: 0.8962\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0859 - accuracy: 0.9032\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1117 - accuracy: 0.8674\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9151\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9143\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9285\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0844 - accuracy: 0.9031\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.9076\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0786 - accuracy: 0.9291\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.8996\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0790 - accuracy: 0.9144\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0630 - accuracy: 0.9208\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9399\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0763 - accuracy: 0.9082\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9199\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0754 - accuracy: 0.9130\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9321\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0768 - accuracy: 0.8826\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0569 - accuracy: 0.9285\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0860 - accuracy: 0.8944\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0646 - accuracy: 0.9369\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0528 - accuracy: 0.9622\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0550 - accuracy: 0.9354\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0575 - accuracy: 0.9569\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0430 - accuracy: 0.9466\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0512 - accuracy: 0.9608\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9211\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9592\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0519 - accuracy: 0.9637\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9703\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0308 - accuracy: 0.9742\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0488 - accuracy: 0.9593\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9457\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0324 - accuracy: 0.9827\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0334 - accuracy: 0.9769\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0408 - accuracy: 0.9794\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0384 - accuracy: 0.9804\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9739\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0410 - accuracy: 0.9782\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0306 - accuracy: 0.9830\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0440 - accuracy: 0.9583\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9747\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9847\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0336 - accuracy: 0.9754\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9874\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0381 - accuracy: 0.9669\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0278 - accuracy: 0.9855\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9752\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 0.9919\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9914\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0300 - accuracy: 0.9834\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0215 - accuracy: 0.9826\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0173 - accuracy: 0.9936\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9889\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0228 - accuracy: 0.9928\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0225 - accuracy: 0.9936\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0231 - accuracy: 0.9842\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0236 - accuracy: 0.9931\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0187 - accuracy: 0.9981\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0224 - accuracy: 0.9871\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0285 - accuracy: 0.9810\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9941\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0196 - accuracy: 0.9993\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0158 - accuracy: 0.9870\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9931\n",
            "1/1 [==============================] - 1s 546ms/step - loss: 0.0757 - accuracy: 0.9048\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 1ms/step - loss: 0.2529 - accuracy: 0.5701\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2550 - accuracy: 0.4992\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2380 - accuracy: 0.5505\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2274 - accuracy: 0.6028\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2213 - accuracy: 0.6723\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2280 - accuracy: 0.6399\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2181 - accuracy: 0.6563\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1999 - accuracy: 0.6979\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1863 - accuracy: 0.6956\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1909 - accuracy: 0.7142\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1871 - accuracy: 0.7048\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1710 - accuracy: 0.7577\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1665 - accuracy: 0.7141\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1623 - accuracy: 0.7412\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1352 - accuracy: 0.8291\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1416 - accuracy: 0.8259\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1512 - accuracy: 0.7748\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1390 - accuracy: 0.7869\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1471 - accuracy: 0.8047\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1064 - accuracy: 0.8963\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1312 - accuracy: 0.8481\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1281 - accuracy: 0.8304\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1234 - accuracy: 0.8580\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1251 - accuracy: 0.8460\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1366 - accuracy: 0.7976\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1089 - accuracy: 0.8633\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1097 - accuracy: 0.8592\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.8920\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0913 - accuracy: 0.9254\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0971 - accuracy: 0.8915\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1112 - accuracy: 0.8659\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1215 - accuracy: 0.8367\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1078 - accuracy: 0.8915\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0914 - accuracy: 0.9026\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1094 - accuracy: 0.8663\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.8996\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.9009\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0990 - accuracy: 0.8872\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0812 - accuracy: 0.9429\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9133\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0960 - accuracy: 0.9004\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.8747\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.9220\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9320\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1047 - accuracy: 0.8867\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0829 - accuracy: 0.9298\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0548 - accuracy: 0.9671\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0688 - accuracy: 0.9109\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0730 - accuracy: 0.9335\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0796 - accuracy: 0.8924\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0921 - accuracy: 0.8955\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0624 - accuracy: 0.9635\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0760 - accuracy: 0.9096\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0649 - accuracy: 0.9523\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9306\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0641 - accuracy: 0.9092\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9570\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0591 - accuracy: 0.9380\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0544 - accuracy: 0.9605\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0529 - accuracy: 0.9291\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0562 - accuracy: 0.9330\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9298\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0651 - accuracy: 0.9114\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0728 - accuracy: 0.9314\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9574\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0493 - accuracy: 0.9331\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9550\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9488\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0393 - accuracy: 0.9698\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9796\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.9850\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9487\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9642\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0441 - accuracy: 0.9583\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0378 - accuracy: 0.9775\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9461\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0514 - accuracy: 0.9584\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0428 - accuracy: 0.9699\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0416 - accuracy: 0.9840\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0406 - accuracy: 0.9684\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0415 - accuracy: 0.9732\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 0.9786\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9841\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0302 - accuracy: 0.9791\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0275 - accuracy: 0.9810\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0220 - accuracy: 0.9911\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0270 - accuracy: 0.9807\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9847\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0335 - accuracy: 0.9748\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0350 - accuracy: 0.9641\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9776\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0273 - accuracy: 0.9886\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0294 - accuracy: 0.9852\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0250 - accuracy: 0.9898\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0174 - accuracy: 0.9841\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0299 - accuracy: 0.9862\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9951\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9876\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0234 - accuracy: 0.9889\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9868\n",
            "1/1 [==============================] - 0s 225ms/step - loss: 0.1343 - accuracy: 0.8571\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 1ms/step - loss: 0.2426 - accuracy: 0.6187\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2351 - accuracy: 0.6517\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2239 - accuracy: 0.6609\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2131 - accuracy: 0.6685\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2151 - accuracy: 0.7102\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2189 - accuracy: 0.5976\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2048 - accuracy: 0.6430\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1780 - accuracy: 0.7870\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1675 - accuracy: 0.7578\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1812 - accuracy: 0.7771\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1572 - accuracy: 0.7883\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1694 - accuracy: 0.7480\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1402 - accuracy: 0.8549\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1544 - accuracy: 0.7731\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1369 - accuracy: 0.8116\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.8367\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.8095\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1353 - accuracy: 0.8163\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1447 - accuracy: 0.7851\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8575\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.8207\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1198 - accuracy: 0.8917\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8591\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1120 - accuracy: 0.8588\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1186 - accuracy: 0.8508\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1137 - accuracy: 0.8709\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1066 - accuracy: 0.9033\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0934 - accuracy: 0.8936\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.8652\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1052 - accuracy: 0.8944\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0993 - accuracy: 0.9248\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1318 - accuracy: 0.8395\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0988 - accuracy: 0.8734\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9214\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.8941\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9215\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0931 - accuracy: 0.8530\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1000 - accuracy: 0.8751\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0904 - accuracy: 0.8822\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9391\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1053 - accuracy: 0.8622\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0941 - accuracy: 0.8999\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9090\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9271\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0981 - accuracy: 0.8706\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0996 - accuracy: 0.8798\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0662 - accuracy: 0.9294\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9077\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0916 - accuracy: 0.8900\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0700 - accuracy: 0.9365\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.8661\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0704 - accuracy: 0.9107\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9149\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0666 - accuracy: 0.9094\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0891 - accuracy: 0.8826\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0615 - accuracy: 0.9284\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0650 - accuracy: 0.9270\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0616 - accuracy: 0.9068\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0743 - accuracy: 0.9018\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0490 - accuracy: 0.9273\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0552 - accuracy: 0.9600\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9100\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9702\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0626 - accuracy: 0.9223\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0579 - accuracy: 0.9612\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0468 - accuracy: 0.9359\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9411\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9258\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0407 - accuracy: 0.9748\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9419\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0419 - accuracy: 0.9679\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9746\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0555 - accuracy: 0.9422\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0360 - accuracy: 0.9696\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9458\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0427 - accuracy: 0.9820\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9586\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0485 - accuracy: 0.9499\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9759\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9786\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0359 - accuracy: 0.9767\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9625\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0305 - accuracy: 0.9769\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0398 - accuracy: 0.9724\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9766\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0280 - accuracy: 0.9843\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0312 - accuracy: 0.9706\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9655\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0194 - accuracy: 0.9934\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9725\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0237 - accuracy: 0.9884\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9810\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0314 - accuracy: 0.9869\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0258 - accuracy: 0.9867\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0253 - accuracy: 0.9823\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9757\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0237 - accuracy: 0.9870\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0171 - accuracy: 0.9908\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9983\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9946\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.0873 - accuracy: 0.9048\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.5817\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.5586\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2341 - accuracy: 0.5755\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2208 - accuracy: 0.5973\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2166 - accuracy: 0.6865\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2201 - accuracy: 0.6849\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2022 - accuracy: 0.7121\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1833 - accuracy: 0.8095\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1808 - accuracy: 0.7758\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1721 - accuracy: 0.7718\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1567 - accuracy: 0.8277\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1516 - accuracy: 0.8263\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1344 - accuracy: 0.8321\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1421 - accuracy: 0.7967\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1301 - accuracy: 0.8116\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1258 - accuracy: 0.7998\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1364 - accuracy: 0.7888\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1337 - accuracy: 0.8437\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1151 - accuracy: 0.8567\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1165 - accuracy: 0.8118\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1328 - accuracy: 0.7926\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.8103\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1240 - accuracy: 0.8482\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1156 - accuracy: 0.8446\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1212 - accuracy: 0.8096\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8420\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1290 - accuracy: 0.7963\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1080 - accuracy: 0.8411\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1132 - accuracy: 0.8690\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0984 - accuracy: 0.8646\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1074 - accuracy: 0.8541\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.7947\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1272 - accuracy: 0.7833\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.8608\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1024 - accuracy: 0.8534\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1142 - accuracy: 0.8089\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0979 - accuracy: 0.8825\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0964 - accuracy: 0.8492\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0977 - accuracy: 0.8463\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.8615\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.8858\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1159 - accuracy: 0.8301\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.8537\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1034 - accuracy: 0.8888\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.8397\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1028 - accuracy: 0.8754\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0925 - accuracy: 0.8869\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9009\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0817 - accuracy: 0.9000\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0771 - accuracy: 0.8795\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0965 - accuracy: 0.8637\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0705 - accuracy: 0.9111\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0881 - accuracy: 0.8927\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0987 - accuracy: 0.8534\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0982 - accuracy: 0.8540\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0846 - accuracy: 0.9056\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0698 - accuracy: 0.9386\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9066\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0802 - accuracy: 0.9043\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0665 - accuracy: 0.9292\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0821 - accuracy: 0.8863\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0567 - accuracy: 0.9398\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.8714\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0935 - accuracy: 0.8893\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0742 - accuracy: 0.9212\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9097\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0631 - accuracy: 0.9406\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0618 - accuracy: 0.9374\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0729 - accuracy: 0.9171\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0740 - accuracy: 0.9028\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9368\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0605 - accuracy: 0.9477\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0694 - accuracy: 0.8847\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0612 - accuracy: 0.9228\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9184\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9159\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0598 - accuracy: 0.9324\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0557 - accuracy: 0.9559\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9477\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0601 - accuracy: 0.9481\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9365\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0682 - accuracy: 0.9331\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9327\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0474 - accuracy: 0.9672\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0557 - accuracy: 0.9516\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9684\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0591 - accuracy: 0.9445\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9683\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0510 - accuracy: 0.9520\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0625 - accuracy: 0.9254\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0537 - accuracy: 0.9425\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9636\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0653 - accuracy: 0.9205\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0568 - accuracy: 0.9422\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9545\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0464 - accuracy: 0.9586\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0373 - accuracy: 0.9616\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9416\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0379 - accuracy: 0.9750\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9548\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.2021 - accuracy: 0.7143\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 0.2540 - accuracy: 0.4936\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2329 - accuracy: 0.6912\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2205 - accuracy: 0.6700\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2108 - accuracy: 0.7444\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2053 - accuracy: 0.7769\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1987 - accuracy: 0.7469\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1884 - accuracy: 0.7316\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1668 - accuracy: 0.8141\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1618 - accuracy: 0.7809\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1595 - accuracy: 0.7994\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1569 - accuracy: 0.7951\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1463 - accuracy: 0.8290\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1250 - accuracy: 0.8522\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.7708\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1362 - accuracy: 0.8078\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.8940\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1272 - accuracy: 0.8316\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1172 - accuracy: 0.8269\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.8551\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1002 - accuracy: 0.9039\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1174 - accuracy: 0.8495\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.9059\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1046 - accuracy: 0.8626\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1010 - accuracy: 0.8808\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1029 - accuracy: 0.8609\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0910 - accuracy: 0.9125\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9020\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0803 - accuracy: 0.8912\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0755 - accuracy: 0.8995\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0819 - accuracy: 0.9066\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.9148\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1077 - accuracy: 0.8622\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0758 - accuracy: 0.9087\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0659 - accuracy: 0.9175\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0547 - accuracy: 0.9528\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0676 - accuracy: 0.9275\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9021\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9420\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0533 - accuracy: 0.9538\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0564 - accuracy: 0.9459\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9257\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9624\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0530 - accuracy: 0.9476\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9521\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9384\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0634 - accuracy: 0.9453\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9465\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0479 - accuracy: 0.9489\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0402 - accuracy: 0.9720\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.9571\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0491 - accuracy: 0.9531\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9818\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0385 - accuracy: 0.9765\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0473 - accuracy: 0.9630\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0451 - accuracy: 0.9721\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9403\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0262 - accuracy: 0.9935\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9601\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9673\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9972\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9875\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0319 - accuracy: 0.9831\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9810\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0477 - accuracy: 0.9520\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0259 - accuracy: 0.9854\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9906\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0180 - accuracy: 0.9889\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9925\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0170 - accuracy: 0.9852\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0153 - accuracy: 0.9978\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9897\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0208 - accuracy: 0.9768\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0221 - accuracy: 0.9856\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0160 - accuracy: 0.9969\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0151 - accuracy: 0.9955\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9876\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0139 - accuracy: 0.9937\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9977\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0189 - accuracy: 0.9876\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0141 - accuracy: 0.9833\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0068 - accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0093 - accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0094 - accuracy: 0.9971\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9985\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0056 - accuracy: 0.9994\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0085 - accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0069 - accuracy: 0.9958\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0064 - accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0055 - accuracy: 1.0000\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7f90d9005950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 203ms/step - loss: 0.0672 - accuracy: 0.8571\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 0.2381 - accuracy: 0.5669\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2323 - accuracy: 0.6572\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2212 - accuracy: 0.6727\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2012 - accuracy: 0.6966\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1985 - accuracy: 0.7513\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1946 - accuracy: 0.7232\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1914 - accuracy: 0.7488\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1832 - accuracy: 0.7700\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1479 - accuracy: 0.7955\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1570 - accuracy: 0.8117\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1539 - accuracy: 0.8413\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1502 - accuracy: 0.7984\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1357 - accuracy: 0.8662\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1493 - accuracy: 0.7829\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1283 - accuracy: 0.8393\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1001 - accuracy: 0.8950\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.8353\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1327 - accuracy: 0.8211\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.8721\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.8591\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1220 - accuracy: 0.8574\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1131 - accuracy: 0.8576\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.9189\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9283\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.8706\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1051 - accuracy: 0.8913\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.8984\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0882 - accuracy: 0.8824\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0863 - accuracy: 0.8961\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0834 - accuracy: 0.9284\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.9162\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0951 - accuracy: 0.9031\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0687 - accuracy: 0.9275\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9555\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0794 - accuracy: 0.9216\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0811 - accuracy: 0.9170\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9377\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0997 - accuracy: 0.8813\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0713 - accuracy: 0.9354\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0677 - accuracy: 0.9489\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0801 - accuracy: 0.9322\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0867 - accuracy: 0.9301\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0779 - accuracy: 0.9259\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0643 - accuracy: 0.9456\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9324\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9177\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9532\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0527 - accuracy: 0.9561\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0795 - accuracy: 0.9212\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9443\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0560 - accuracy: 0.9524\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0598 - accuracy: 0.9470\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0658 - accuracy: 0.9448\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9370\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9234\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0543 - accuracy: 0.9425\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0500 - accuracy: 0.9586\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9355\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9496\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0390 - accuracy: 0.9417\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9396\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0541 - accuracy: 0.9568\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0627 - accuracy: 0.9550\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9555\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0480 - accuracy: 0.9662\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.9765\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0559 - accuracy: 0.9537\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9387\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0432 - accuracy: 0.9672\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0503 - accuracy: 0.9700\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0452 - accuracy: 0.9603\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0576 - accuracy: 0.9433\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0541 - accuracy: 0.9657\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9646\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9569\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9906\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0307 - accuracy: 0.9793\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0273 - accuracy: 0.9772\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9884\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0186 - accuracy: 0.9794\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9670\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0395 - accuracy: 0.9663\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0263 - accuracy: 0.9836\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0267 - accuracy: 0.9843\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0288 - accuracy: 0.9848\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0300 - accuracy: 0.9808\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0319 - accuracy: 0.9710\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0282 - accuracy: 0.9800\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9823\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0317 - accuracy: 0.9783\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 0.9841\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9816\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9838\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0279 - accuracy: 0.9813\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9528\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0229 - accuracy: 0.9856\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 0.9860\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0322 - accuracy: 0.9816\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0168 - accuracy: 0.9910\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9908\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7f90d28055f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.2711 - accuracy: 0.6667\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 1ms/step - loss: 0.2676 - accuracy: 0.4629\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2409 - accuracy: 0.7170\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2369 - accuracy: 0.6851\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2319 - accuracy: 0.6779\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2234 - accuracy: 0.6988\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2192 - accuracy: 0.7156\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2129 - accuracy: 0.6732\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1861 - accuracy: 0.7685\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1779 - accuracy: 0.7654\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1706 - accuracy: 0.7913\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1698 - accuracy: 0.7980\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1622 - accuracy: 0.7941\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1515 - accuracy: 0.8249\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1749 - accuracy: 0.7094\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1440 - accuracy: 0.8291\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.8237\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1386 - accuracy: 0.7956\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1405 - accuracy: 0.7903\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1482 - accuracy: 0.7387\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1239 - accuracy: 0.8366\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.8055\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.7922\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1286 - accuracy: 0.8441\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1191 - accuracy: 0.8013\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1424 - accuracy: 0.7436\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1203 - accuracy: 0.8514\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.7845\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1084 - accuracy: 0.8523\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1127 - accuracy: 0.8285\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.8522\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.8472\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1129 - accuracy: 0.8340\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.8730\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0864 - accuracy: 0.9102\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1122 - accuracy: 0.8347\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.8740\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1141 - accuracy: 0.8155\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1013 - accuracy: 0.8836\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0911 - accuracy: 0.8637\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1016 - accuracy: 0.8501\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0947 - accuracy: 0.8894\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.8789\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.8804\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9284\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.8413\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.8820\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.9599\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0930 - accuracy: 0.8510\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0770 - accuracy: 0.8974\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.9137\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0855 - accuracy: 0.8939\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0732 - accuracy: 0.8938\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.8918\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0653 - accuracy: 0.9300\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0789 - accuracy: 0.8899\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0727 - accuracy: 0.9217\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0614 - accuracy: 0.9474\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9547\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9058\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9573\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 0.9535\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0729 - accuracy: 0.9026\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0697 - accuracy: 0.9285\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0605 - accuracy: 0.9294\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0622 - accuracy: 0.9394\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.9773\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0636 - accuracy: 0.9029\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0444 - accuracy: 0.9636\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0436 - accuracy: 0.9445\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9550\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0561 - accuracy: 0.9285\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9654\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.9691\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9500\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0496 - accuracy: 0.9463\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9582\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0533 - accuracy: 0.9303\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0434 - accuracy: 0.9562\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.9683\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9794\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0485 - accuracy: 0.9710\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9717\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.9873\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9860\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9756\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0266 - accuracy: 0.9842\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9728\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0251 - accuracy: 0.9898\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0228 - accuracy: 0.9911\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0276 - accuracy: 0.9699\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9762\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9722\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0321 - accuracy: 0.9767\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9922\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9819\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0334 - accuracy: 0.9757\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0226 - accuracy: 0.9886\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9939\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0202 - accuracy: 0.9863\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0187 - accuracy: 0.9856\n",
            "1/1 [==============================] - 0s 208ms/step - loss: 0.1203 - accuracy: 0.7619\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 0.2462 - accuracy: 0.5534\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2392 - accuracy: 0.5549\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2307 - accuracy: 0.5967\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2211 - accuracy: 0.7197\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2161 - accuracy: 0.7185\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2137 - accuracy: 0.7176\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2001 - accuracy: 0.7588\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1938 - accuracy: 0.7306\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1817 - accuracy: 0.7795\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1744 - accuracy: 0.7702\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1760 - accuracy: 0.7297\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1505 - accuracy: 0.8192\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.8010\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1433 - accuracy: 0.8583\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1434 - accuracy: 0.8498\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1530 - accuracy: 0.7711\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.8193\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.8299\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1301 - accuracy: 0.8547\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1275 - accuracy: 0.8606\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1335 - accuracy: 0.8494\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1219 - accuracy: 0.8243\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.8944\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.8117\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1032 - accuracy: 0.8669\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1146 - accuracy: 0.8589\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1216 - accuracy: 0.8393\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0976 - accuracy: 0.8590\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0959 - accuracy: 0.8945\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1079 - accuracy: 0.9091\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1160 - accuracy: 0.8384\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9207\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.8710\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0852 - accuracy: 0.9073\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9122\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0897 - accuracy: 0.8987\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0833 - accuracy: 0.8932\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9099\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.8880\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9089\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9214\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0853 - accuracy: 0.8858\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0817 - accuracy: 0.9121\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9199\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0706 - accuracy: 0.9440\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9209\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9340\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.8877\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9599\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0603 - accuracy: 0.9094\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0595 - accuracy: 0.9369\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9315\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0584 - accuracy: 0.9613\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9354\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0647 - accuracy: 0.9211\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0712 - accuracy: 0.9142\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9309\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0573 - accuracy: 0.9518\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9183\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0558 - accuracy: 0.9545\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9491\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0455 - accuracy: 0.9618\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 0.9433\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9273\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0680 - accuracy: 0.9208\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0410 - accuracy: 0.9562\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0525 - accuracy: 0.9431\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9369\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0464 - accuracy: 0.9629\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0429 - accuracy: 0.9749\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0349 - accuracy: 0.9691\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 0.9857\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.9745\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0297 - accuracy: 0.9789\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0589 - accuracy: 0.9445\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 0.9825\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0289 - accuracy: 0.9825\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9682\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9773\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0364 - accuracy: 0.9800\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.9833\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9738\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9698\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 0.9668\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9590\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.9840\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9775\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0189 - accuracy: 0.9951\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9912\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9706\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 0.9925\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0318 - accuracy: 0.9849\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0340 - accuracy: 0.9612\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9916\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9717\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0229 - accuracy: 0.9870\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9937\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0264 - accuracy: 0.9826\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0173 - accuracy: 0.9953\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9864\n",
            "1/1 [==============================] - 0s 211ms/step - loss: 0.0397 - accuracy: 0.9000\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 2ms/step - loss: 0.2611 - accuracy: 0.4660\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2445 - accuracy: 0.5796\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.2338 - accuracy: 0.5885\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2258 - accuracy: 0.7151\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2124 - accuracy: 0.7195\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.7310\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1894 - accuracy: 0.7377\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.8195\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.7711\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.8337\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1594 - accuracy: 0.7914\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1391 - accuracy: 0.8363\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1342 - accuracy: 0.8359\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1278 - accuracy: 0.8494\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.8550\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1246 - accuracy: 0.8294\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1370 - accuracy: 0.8346\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1208 - accuracy: 0.8246\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.8725\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1225 - accuracy: 0.8277\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1202 - accuracy: 0.8242\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1090 - accuracy: 0.8556\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.8624\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1011 - accuracy: 0.8833\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0920 - accuracy: 0.8849\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0961 - accuracy: 0.8762\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.8915\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0842 - accuracy: 0.9013\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0824 - accuracy: 0.9133\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1034 - accuracy: 0.8854\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.8569\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9016\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0786 - accuracy: 0.9375\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0810 - accuracy: 0.9034\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0826 - accuracy: 0.8951\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0809 - accuracy: 0.8785\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0696 - accuracy: 0.9294\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9177\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0606 - accuracy: 0.9597\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0579 - accuracy: 0.9542\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0543 - accuracy: 0.9489\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9322\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0574 - accuracy: 0.9413\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0735 - accuracy: 0.8998\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0518 - accuracy: 0.9383\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0695 - accuracy: 0.9277\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9562\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0639 - accuracy: 0.9369\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0531 - accuracy: 0.9437\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.9639\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.9717\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9719\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9510\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9522\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9215\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9402\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9407\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9425\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9870\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0505 - accuracy: 0.9496\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9513\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0446 - accuracy: 0.9557\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.9738\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0457 - accuracy: 0.9362\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0357 - accuracy: 0.9800\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9761\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.9750\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0478 - accuracy: 0.9483\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.9459\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0293 - accuracy: 0.9700\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0487 - accuracy: 0.9431\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9815\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0502 - accuracy: 0.9413\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9683\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 0.9781\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0214 - accuracy: 0.9871\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0238 - accuracy: 0.9915\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0304 - accuracy: 0.9792\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9693\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9867\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9801\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 0.9718\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0256 - accuracy: 0.9817\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9689\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0314 - accuracy: 0.9904\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0170 - accuracy: 0.9855\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0211 - accuracy: 0.9871\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 0.9898\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0169 - accuracy: 0.9905\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.9707\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9775\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0240 - accuracy: 0.9814\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 0.9825\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9828\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0283 - accuracy: 0.9654\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9882\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0356 - accuracy: 0.9496\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 0.9848\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 0.9827\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0217 - accuracy: 0.9796\n",
            "1/1 [==============================] - 0s 217ms/step - loss: 0.1784 - accuracy: 0.7500\n",
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 1ms/step - loss: 0.2462 - accuracy: 0.5520\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2414 - accuracy: 0.5337\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2370 - accuracy: 0.5559\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2302 - accuracy: 0.5897\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2293 - accuracy: 0.6121\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2283 - accuracy: 0.6042\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2170 - accuracy: 0.6868\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2146 - accuracy: 0.7221\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2026 - accuracy: 0.6453\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2034 - accuracy: 0.7764\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1959 - accuracy: 0.6838\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1753 - accuracy: 0.7538\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1845 - accuracy: 0.7465\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1623 - accuracy: 0.8180\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1649 - accuracy: 0.7834\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.7584\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.1607 - accuracy: 0.7616\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1355 - accuracy: 0.8280\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1411 - accuracy: 0.8345\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1192 - accuracy: 0.8536\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.8132\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1250 - accuracy: 0.8577\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1184 - accuracy: 0.8673\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1219 - accuracy: 0.8608\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.8686\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1267 - accuracy: 0.8525\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.8836\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9083\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.8931\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1134 - accuracy: 0.8480\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.8816\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.8280\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0857 - accuracy: 0.9283\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9260\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9167\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0816 - accuracy: 0.9267\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0986 - accuracy: 0.8943\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0856 - accuracy: 0.9079\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9252\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9225\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0791 - accuracy: 0.8984\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0684 - accuracy: 0.9386\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0780 - accuracy: 0.9138\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.8781\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9354\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0720 - accuracy: 0.9389\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0577 - accuracy: 0.9489\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9381\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9486\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0565 - accuracy: 0.9387\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9613\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0784 - accuracy: 0.8997\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0508 - accuracy: 0.9735\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.9574\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0546 - accuracy: 0.9608\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9510\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0509 - accuracy: 0.9639\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0599 - accuracy: 0.9428\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0702 - accuracy: 0.9231\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.9629\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0495 - accuracy: 0.9566\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0472 - accuracy: 0.9545\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9494\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9413\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9441\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0420 - accuracy: 0.9679\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0608 - accuracy: 0.9283\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0547 - accuracy: 0.9534\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0463 - accuracy: 0.9560\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.9519\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0255 - accuracy: 0.9888\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 0.9866\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0325 - accuracy: 0.9723\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0269 - accuracy: 0.9769\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0523 - accuracy: 0.9556\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9881\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0298 - accuracy: 0.9696\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 0.9857\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0422 - accuracy: 0.9666\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.9699\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0299 - accuracy: 0.9779\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0254 - accuracy: 0.9691\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.9734\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0244 - accuracy: 0.9842\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9872\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9785\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9868\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0203 - accuracy: 0.9965\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0199 - accuracy: 0.9944\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0313 - accuracy: 0.9810\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0206 - accuracy: 0.9859\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 0.9937\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0308 - accuracy: 0.9806\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0162 - accuracy: 0.9932\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 0.9780\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0127 - accuracy: 0.9953\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0148 - accuracy: 0.9895\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9764\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 1ms/step - loss: 0.0130 - accuracy: 0.9930\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0263 - accuracy: 0.9824\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.1570 - accuracy: 0.8500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqRflnBBcin7",
        "outputId": "2edaa6b5-b003-49eb-927c-e0a8ca064681"
      },
      "source": [
        "# 결과 출력\n",
        "print(\"\\n %.f fold accuracy:\" % n_fold, accuracy)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 10 fold accuracy: ['0.9048', '0.8571', '0.9048', '0.7143', '0.8571', '0.6667', '0.7619', '0.9000', '0.7500', '0.8500']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwBLEldTeFfd"
      },
      "source": [
        "10번의 테스트가 모두 정상 작동이 되었다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Rw2Z8fWeTqJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}