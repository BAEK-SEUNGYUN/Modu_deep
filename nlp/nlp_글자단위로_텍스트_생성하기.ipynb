{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_글자단위로 텍스트 생성하기.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1XYqpKwkUnFdau9PpBIvBbTSkyNGehdyW",
      "authorship_tag": "ABX9TyM2Mg0qKS7YkI/RsThcEwgw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BAEK-SEUNGYUN/modu_deep/blob/main/nlp_%EA%B8%80%EC%9E%90%EB%8B%A8%EC%9C%84%EB%A1%9C_%ED%85%8D%EC%8A%A4%ED%8A%B8_%EC%83%9D%EC%84%B1%ED%95%98%EA%B8%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JGIeXm2UDSx"
      },
      "source": [
        "# '경마장에 말이 달리고 있다.'\n",
        "# 경마장에\n",
        "# 말이\n",
        "# 달리고\n",
        "# 있다.\n",
        "#단어단위\n",
        "\n",
        "\n",
        "# 글자단위\n",
        "# 경\n",
        "# 마\n",
        "# 장\n",
        "# 에\n",
        "# 말\n",
        "# 이\n",
        "# 달\n",
        "# 리\n",
        "# 고\n",
        "# 있\n",
        "# 다\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5XLOuxPXtMP"
      },
      "source": [
        "## 글자 단위 RNN 언어 모델\n",
        "\n",
        "![r](https://wikidocs.net/images/page/48649/char_rnn1.PNG)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o1PUEHMXpMO"
      },
      "source": [
        "import numpy as np\n",
        "import urllib.request\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0D16ey-hYBX8",
        "outputId": "a9bf157d-4d81-4f50-bbce-159e0825ced0"
      },
      "source": [
        "urllib.request.urlretrieve(\"http://www.gutenberg.org/files/11/11-0.txt\", filename=\"11-0.txt\")\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('11-0.txt', <http.client.HTTPMessage at 0x7f3dcb0f87d0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5tfclf4YGQE"
      },
      "source": [
        "f = open('11-0.txt', 'rb')\n",
        "lines = []\n",
        "for line in f:\n",
        "  line = line.strip()   # strip을 통해 \\r, \\n 제거\n",
        "  line = line.lower()   # 소문자화\n",
        "  line = line.decode('ascii','ignore')    # \\we2\\x80\\x99등과 같은 바이트 열 제거\n",
        "  if len(line) > 0:\n",
        "    lines.append(line)\n",
        "\n",
        "f.close()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pD_3ezC7Yl_p",
        "outputId": "ac128b30-013b-4cd4-e5b7-8e2562b44082"
      },
      "source": [
        "lines[:5]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the project gutenberg ebook of alices adventures in wonderland, by lewis carroll',\n",
              " 'this ebook is for the use of anyone anywhere in the united states and',\n",
              " 'most other parts of the world at no cost and with almost no restrictions',\n",
              " 'whatsoever. you may copy it, give it away or re-use it under the terms',\n",
              " 'of the project gutenberg license included with this ebook or online at']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHXEelC0YoSW",
        "outputId": "0fbfb24d-847a-4220-861b-c0e0bf394ab0"
      },
      "source": [
        "# 하나의 문자열로 통합\n",
        "text = ' '.join(lines)\n",
        "print('문자열의 길이 또는 총 글자의 갯수 : %d' %len(text))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문자열의 길이 또는 총 글자의 갯수 : 159484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDtozuJEYzuf",
        "outputId": "47e69c4c-c357-4e1b-d552-b035cf2dac3c"
      },
      "source": [
        "print(text[:100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the project gutenberg ebook of alices adventures in wonderland, by lewis carroll this ebook is for t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acg-tcDfY3HS",
        "outputId": "7f0c9574-c1c2-4985-8126-e05864607d9f"
      },
      "source": [
        "# 글자 집합을 만들어보자\n",
        "char_vocab = sorted(list(set(text)))\n",
        "vocab_size = len(char_vocab)\n",
        "print('글자 집합의 크기 : {}'.format(vocab_size))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7iGFYIjuZQ12",
        "outputId": "fa56502b-419f-4386-8424-18b26203d145"
      },
      "source": [
        "print(char_vocab)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', '!', '\"', '#', '$', '%', \"'\", '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SpV367XZX2V",
        "outputId": "39a7960e-d02d-491c-ee0a-899a2f0d2ab7"
      },
      "source": [
        "# 글자 집합에 인덱스를 부여하고 전부 출력하기\n",
        "char_to_index = dict((c,i) for i,c in enumerate(char_vocab))\n",
        "print(char_to_index)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, '!': 1, '\"': 2, '#': 3, '$': 4, '%': 5, \"'\": 6, '(': 7, ')': 8, '*': 9, ',': 10, '-': 11, '.': 12, '/': 13, '0': 14, '1': 15, '2': 16, '3': 17, '4': 18, '5': 19, '6': 20, '7': 21, '8': 22, '9': 23, ':': 24, ';': 25, '?': 26, '[': 27, ']': 28, '_': 29, 'a': 30, 'b': 31, 'c': 32, 'd': 33, 'e': 34, 'f': 35, 'g': 36, 'h': 37, 'i': 38, 'j': 39, 'k': 40, 'l': 41, 'm': 42, 'n': 43, 'o': 44, 'p': 45, 'q': 46, 'r': 47, 's': 48, 't': 49, 'u': 50, 'v': 51, 'w': 52, 'x': 53, 'y': 54, 'z': 55}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcx7xMlxZvEd"
      },
      "source": [
        "# 인덱스로부터 글자를 리턴하기\n",
        "index_to_char = {}\n",
        "for key, value in char_to_index.items():\n",
        "  index_to_char[value] = key"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPRYkU8iaUgY",
        "outputId": "913cd658-e12a-46bd-f4d3-86f0297844ec"
      },
      "source": [
        "  print(index_to_char)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: ' ', 1: '!', 2: '\"', 3: '#', 4: '$', 5: '%', 6: \"'\", 7: '(', 8: ')', 9: '*', 10: ',', 11: '-', 12: '.', 13: '/', 14: '0', 15: '1', 16: '2', 17: '3', 18: '4', 19: '5', 20: '6', 21: '7', 22: '8', 23: '9', 24: ':', 25: ';', 26: '?', 27: '[', 28: ']', 29: '_', 30: 'a', 31: 'b', 32: 'c', 33: 'd', 34: 'e', 35: 'f', 36: 'g', 37: 'h', 38: 'i', 39: 'j', 40: 'k', 41: 'l', 42: 'm', 43: 'n', 44: 'o', 45: 'p', 46: 'q', 47: 'r', 48: 's', 49: 't', 50: 'u', 51: 'v', 52: 'w', 53: 'x', 54: 'y', 55: 'z'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dXotoj_ajFR"
      },
      "source": [
        "# 훈련데이터를 구성\n",
        "# apple \n",
        "# sample의 길이 4\n",
        "\n",
        "# example) 샘플의 길이가 4라면 4개의 입력 글자 시퀀스로부터 4개의 출력 글자 시퀀스 예측. 즉 RNN의 time step은 4번\n",
        "# appl -> pple\n",
        "# appl (입력시퀀스, train_x), pple(예측해야하는 시퀀스, train_y)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIKyEtuIe2l0",
        "outputId": "ed440896-cd35-42da-b56b-190073db6f9c"
      },
      "source": [
        "# 15만 8천의 길이를 가진 text문자열로부터 다수의 문장 샘플들로 분리\n",
        "# 분리하는 방법은 문장 샘플의 길이를 정하고, 해당 길이만큼 문자열 전부를 전부 등분 하는 것!!\n",
        "seq_length = 60\n",
        "n_samples = int(np.floor((len(text)-1)/seq_length)) #문자열을 60등분한다 ---> 총 샘플의 수\n",
        "print('문장 샘플의 수 : {}'.format(n_samples))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "문장 샘플의 수 : 2658\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdfLoCi5e3bL"
      },
      "source": [
        "train_x = []\n",
        "train_y = []\n",
        "\n",
        "for i in range(n_samples): # 2658번 수행\n",
        "  x_sample = text[i * seq_length: (i+1)*seq_length] # 문장 샘플을 1개씩 가져온다.\n",
        "  x_encoded = [char_to_index[c] for c in x_sample] # 하나의 문장 샘플에 대해서 정수 인코딩\n",
        "  train_x.append(x_encoded)\n",
        "\n",
        "  y_sample = text[i*seq_length + 1: (i+1) *seq_length + 1] # 오른쪽으로 1칸 쉬프트한다.\n",
        "  y_encoded = [char_to_index[c] for c in y_sample]\n",
        "  train_y.append(y_encoded)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVUbIdTQe4zR",
        "outputId": "6d70af19-8a6c-492a-96e2-c2f4fa46b640"
      },
      "source": [
        "print(train_x[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49, 37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYjJK-jKe59E",
        "outputId": "aab76da3-6361-4879-9a06-813618042137"
      },
      "source": [
        "print(train_y[0])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[37, 34, 0, 45, 47, 44, 39, 34, 32, 49, 0, 36, 50, 49, 34, 43, 31, 34, 47, 36, 0, 34, 31, 44, 44, 40, 0, 44, 35, 0, 30, 41, 38, 32, 34, 48, 0, 30, 33, 51, 34, 43, 49, 50, 47, 34, 48, 0, 38, 43, 0, 52, 44, 43, 33, 34, 47, 41, 30, 43]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHgXc2rde66O",
        "outputId": "134b5b15-9c26-4eef-ae98-d48d914540ce"
      },
      "source": [
        "print(train_x[1])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[43, 33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSAOXREQe78x",
        "outputId": "1ac23dc6-dd85-41e2-f200-7358a3fcc916"
      },
      "source": [
        "print(train_y[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[33, 10, 0, 31, 54, 0, 41, 34, 52, 38, 48, 0, 32, 30, 47, 47, 44, 41, 41, 0, 49, 37, 38, 48, 0, 34, 31, 44, 44, 40, 0, 38, 48, 0, 35, 44, 47, 0, 49, 37, 34, 0, 50, 48, 34, 0, 44, 35, 0, 30, 43, 54, 44, 43, 34, 0, 30, 43, 54, 52]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxmrZQcte9Xm"
      },
      "source": [
        "# x 와 y 에 대해 원-핫 이코딩 수행, 입력 시퀀스에 대해 워드 임베딩 하지 않습니다. -> embedding layer 사용 X\n",
        "train_x = to_categorical(train_x)\n",
        "train_y = to_categorical(train_y)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5x9lVfUiS4d",
        "outputId": "bf348aba-12ec-4928-9818-ad15e1bed953"
      },
      "source": [
        "print('train_x의 크기 (shape) : {}'.format(train_x.shape))\n",
        "print('train_y의 크기 (shape) : {}'.format(train_y.shape))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x의 크기 (shape) : (2658, 60, 56)\n",
            "train_y의 크기 (shape) : (2658, 60, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_CPyo5Skc5S"
      },
      "source": [
        "샘플의 수가 2658, 입력시퀀스의 길이(input_length) 60, 각 벡터의 차원(input_dim) 56 의미  \n",
        "원-핫 벡터의 차원은 글자 집합의 크기인 56\n",
        "\n",
        "![](https://wikidocs.net/images/page/22886/rnn_image6between7.PNG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-mvEW60iXLQ"
      },
      "source": [
        "### 모델 설계하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sl0NOhD0khcQ"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, TimeDistributed"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6touGd0Fkiby"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(None, train_x.shape[2]), return_sequences=True))\n",
        "model.add(LSTM(256, return_sequences=True))\n",
        "model.add(TimeDistributed(Dense(vocab_size, activation='softmax')))"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chwKRuUWkjV2",
        "outputId": "a891e4e8-4d9b-4f17-cc85-f08c74f4fefc"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "model.fit(train_x, train_y, epochs=80, verbose=1)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "84/84 [==============================] - 10s 13ms/step - loss: 3.0714 - accuracy: 0.1818\n",
            "Epoch 2/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.7553 - accuracy: 0.2389\n",
            "Epoch 3/80\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 2.3904 - accuracy: 0.3276\n",
            "Epoch 4/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.2461 - accuracy: 0.3601\n",
            "Epoch 5/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 2.1374 - accuracy: 0.3883\n",
            "Epoch 6/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 2.0543 - accuracy: 0.4097\n",
            "Epoch 7/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.9813 - accuracy: 0.4292\n",
            "Epoch 8/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.9207 - accuracy: 0.4457\n",
            "Epoch 9/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8636 - accuracy: 0.4612\n",
            "Epoch 10/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.8148 - accuracy: 0.4751\n",
            "Epoch 11/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.7688 - accuracy: 0.4865\n",
            "Epoch 12/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.7288 - accuracy: 0.4967\n",
            "Epoch 13/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6899 - accuracy: 0.5069\n",
            "Epoch 14/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.6542 - accuracy: 0.5159\n",
            "Epoch 15/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.6183 - accuracy: 0.5250\n",
            "Epoch 16/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5847 - accuracy: 0.5335\n",
            "Epoch 17/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.5507 - accuracy: 0.5414\n",
            "Epoch 18/80\n",
            "84/84 [==============================] - 1s 14ms/step - loss: 1.5196 - accuracy: 0.5501\n",
            "Epoch 19/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4907 - accuracy: 0.5574\n",
            "Epoch 20/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4609 - accuracy: 0.5657\n",
            "Epoch 21/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4349 - accuracy: 0.5731\n",
            "Epoch 22/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.4066 - accuracy: 0.5807\n",
            "Epoch 23/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3805 - accuracy: 0.5885\n",
            "Epoch 24/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3484 - accuracy: 0.5983\n",
            "Epoch 25/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.3229 - accuracy: 0.6056\n",
            "Epoch 26/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2977 - accuracy: 0.6125\n",
            "Epoch 27/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2691 - accuracy: 0.6203\n",
            "Epoch 28/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2409 - accuracy: 0.6291\n",
            "Epoch 29/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.2185 - accuracy: 0.6351\n",
            "Epoch 30/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1886 - accuracy: 0.6440\n",
            "Epoch 31/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1680 - accuracy: 0.6497\n",
            "Epoch 32/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 1.1399 - accuracy: 0.6587\n",
            "Epoch 33/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.1123 - accuracy: 0.6664\n",
            "Epoch 34/80\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0865 - accuracy: 0.6737\n",
            "Epoch 35/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0592 - accuracy: 0.6821\n",
            "Epoch 36/80\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 1.0313 - accuracy: 0.6903\n",
            "Epoch 37/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 1.0024 - accuracy: 0.6992\n",
            "Epoch 38/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9818 - accuracy: 0.7050\n",
            "Epoch 39/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.9503 - accuracy: 0.7163\n",
            "Epoch 40/80\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 0.9263 - accuracy: 0.7225\n",
            "Epoch 41/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8964 - accuracy: 0.7328\n",
            "Epoch 42/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8737 - accuracy: 0.7391\n",
            "Epoch 43/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.8428 - accuracy: 0.7495\n",
            "Epoch 44/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8301 - accuracy: 0.7521\n",
            "Epoch 45/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.8007 - accuracy: 0.7621\n",
            "Epoch 46/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7741 - accuracy: 0.7709\n",
            "Epoch 47/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7439 - accuracy: 0.7813\n",
            "Epoch 48/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7229 - accuracy: 0.7871\n",
            "Epoch 49/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.7091 - accuracy: 0.7908\n",
            "Epoch 50/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6819 - accuracy: 0.8006\n",
            "Epoch 51/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6550 - accuracy: 0.8091\n",
            "Epoch 52/80\n",
            "84/84 [==============================] - 1s 11ms/step - loss: 0.6314 - accuracy: 0.8169\n",
            "Epoch 53/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.6084 - accuracy: 0.8247\n",
            "Epoch 54/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5896 - accuracy: 0.8310\n",
            "Epoch 55/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5729 - accuracy: 0.8354\n",
            "Epoch 56/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5446 - accuracy: 0.8455\n",
            "Epoch 57/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5223 - accuracy: 0.8528\n",
            "Epoch 58/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.5077 - accuracy: 0.8576\n",
            "Epoch 59/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4947 - accuracy: 0.8616\n",
            "Epoch 60/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4849 - accuracy: 0.8625\n",
            "Epoch 61/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4488 - accuracy: 0.8767\n",
            "Epoch 62/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4272 - accuracy: 0.8852\n",
            "Epoch 63/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4198 - accuracy: 0.8860\n",
            "Epoch 64/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4174 - accuracy: 0.8842\n",
            "Epoch 65/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.4006 - accuracy: 0.8908\n",
            "Epoch 66/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3725 - accuracy: 0.9012\n",
            "Epoch 67/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3542 - accuracy: 0.9075\n",
            "Epoch 68/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3403 - accuracy: 0.9114\n",
            "Epoch 69/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3368 - accuracy: 0.9121\n",
            "Epoch 70/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3155 - accuracy: 0.9194\n",
            "Epoch 71/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3149 - accuracy: 0.9183\n",
            "Epoch 72/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.3140 - accuracy: 0.9176\n",
            "Epoch 73/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2871 - accuracy: 0.9277\n",
            "Epoch 74/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2675 - accuracy: 0.9343\n",
            "Epoch 75/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2820 - accuracy: 0.9271\n",
            "Epoch 76/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2657 - accuracy: 0.9329\n",
            "Epoch 77/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2417 - accuracy: 0.9413\n",
            "Epoch 78/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2370 - accuracy: 0.9423\n",
            "Epoch 79/80\n",
            "84/84 [==============================] - 1s 13ms/step - loss: 0.2374 - accuracy: 0.9410\n",
            "Epoch 80/80\n",
            "84/84 [==============================] - 1s 12ms/step - loss: 0.2262 - accuracy: 0.9446\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d3a417d90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeCEQyzqkkmh"
      },
      "source": [
        "def sentence_generation(model, length):\n",
        "    ix = [np.random.randint(vocab_size)] # 글자에 대한 랜덤 인덱스 생성\n",
        "    y_char = [index_to_char[ix[-1]]] # 랜덤 익덱스로부터 글자 생성\n",
        "    print(ix[-1],'번 글자',y_char[-1],'로 예측을 시작!')\n",
        "    X = np.zeros((1, length, vocab_size)) # (1, length, 55) 크기의 X 생성. 즉, LSTM의 입력 시퀀스 생성\n",
        "\n",
        "    for i in range(length):\n",
        "        X[0][i][ix[-1]] = 1 # X[0][i][예측한 글자의 인덱스] = 1, 즉, 예측 글자를 다음 입력 시퀀스에 추가\n",
        "        print(index_to_char[ix[-1]], end=\"\")\n",
        "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
        "        y_char.append(index_to_char[ix[-1]])\n",
        "    return ('').join(y_char)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "512sIGJcpPrq",
        "outputId": "86910428-314a-4104-e1c8-e51a791fa830"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50 번 글자 u 로 예측을 시작!\n",
            "ut for a minute or two sobs choked his voice. same as if he here the foundatly before she falled in "
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'ut for a minute or two sobs choked his voice. same as if he here the foundatly before she falled in a'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "AXQJR0zhpQvl",
        "outputId": "889b2b95-23fd-49d3-912c-e1fc36a054f1"
      },
      "source": [
        "sentence_generation(model, 30)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48 번 글자 s 로 예측을 시작!\n",
            "s and writing-desks, which was"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'s and writing-desks, which wasn'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "NagGljWSpSf5",
        "outputId": "d72b6cd5-e125-4e30-e47c-e59263872aa3"
      },
      "source": [
        "sentence_generation(model, 100)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42 번 글자 m 로 예측을 시작!\n",
            "maller, i can creep under the door, and forth intheres, but al crowd of little girds of the back. wh"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'maller, i can creep under the door, and forth intheres, but al crowd of little girds of the back. whe'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Xpf7O9F-pTgT",
        "outputId": "9b9e312a-d370-40b4-eb54-b487f42cb3f6"
      },
      "source": [
        "sentence_generation(model, 25)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "35 번 글자 f 로 예측을 시작!\n",
            "f the month, and doing wh"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'f the month, and doing whi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWT2itTmpVSt"
      },
      "source": [
        "## 글자 단위 RNN(Char RNN)으로 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9dxnIz4NtmqQ"
      },
      "source": [
        "다 대 일(many to one)구조의 RNN을 글자 단위로 학습시키고, 텍스트 생성하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4if2qNuytojm"
      },
      "source": [
        "### 데이터에 대한 이해와 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMMtFcZWtsY2"
      },
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGuQLDFOt1LL"
      },
      "source": [
        "text='''\n",
        "I get on with life as a programmer,\n",
        "I like to contemplate beer.\n",
        "But when I start to daydream,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "Do I love wine more than beer?\n",
        "\n",
        "I like to use words about beer.\n",
        "But when I stop my talking,\n",
        "My mind turns straight to wine.\n",
        "\n",
        "I hate bugs and errors.\n",
        "But I just think back to wine,\n",
        "And I'm happy once again.\n",
        "\n",
        "I like to hang out with programming and deep learning.\n",
        "But when left alone,\n",
        "My mind turns straight to wine.\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJLVlsHjt522",
        "outputId": "61252a4e-ba25-4af4-fb4e-2435c1aac23b"
      },
      "source": [
        "tokens = text.split() # '\\n 제거'\n",
        "text = ' '.join(tokens)\n",
        "print(text)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to contemplate beer. But when I start to daydream, My mind turns straight to wine. Do I love wine more than beer? I like to use words about beer. But when I stop my talking, My mind turns straight to wine. I hate bugs and errors. But I just think back to wine, And I'm happy once again. I like to hang out with programming and deep learning. But when left alone, My mind turns straight to wine.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDgLjF7XuLVo",
        "outputId": "82fcab58-89d2-45d4-9b65-970ac367237a"
      },
      "source": [
        "char_vocab = sorted(list(set(text))) # 중복을 제한 글자 집합 생성\n",
        "print(char_vocab)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ', \"'\", ',', '.', '?', 'A', 'B', 'D', 'I', 'M', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'y']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mH_eXb4ucm6",
        "outputId": "6a665081-bc04-4751-a2d3-0d527fdfae0f"
      },
      "source": [
        "vocab_size = len(char_vocab)\n",
        "print(f'글자 집합의 크기 : {vocab_size}')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "글자 집합의 크기 : 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDd3NpOcuxfd",
        "outputId": "49d4bb32-6087-453d-c4a6-4c0819c0699b"
      },
      "source": [
        "char_to_index = dict((c, i) for i,c in enumerate(char_vocab))   # 글자에 고유한 정수 인덱스 부여\n",
        "print(char_to_index)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{' ': 0, \"'\": 1, ',': 2, '.': 3, '?': 4, 'A': 5, 'B': 6, 'D': 7, 'I': 8, 'M': 9, 'a': 10, 'b': 11, 'c': 12, 'd': 13, 'e': 14, 'f': 15, 'g': 16, 'h': 17, 'i': 18, 'j': 19, 'k': 20, 'l': 21, 'm': 22, 'n': 23, 'o': 24, 'p': 25, 'r': 26, 's': 27, 't': 28, 'u': 29, 'v': 30, 'w': 31, 'y': 32}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHgwwW1Yu4t1"
      },
      "source": [
        "# example 5개의 입력 글자 시퀀스로부터 다음 글자 시퀀스를 예측\n",
        "\n",
        "- stude -> n\n",
        "\n",
        "- tuden -> t"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-LrKpW0vMIN",
        "outputId": "d52298ff-fb1b-4f7b-83d5-98df9de08e52"
      },
      "source": [
        "length = 11\n",
        "sequences = []\n",
        "for i in range(length, len(text)):\n",
        "  seq = text[i-length:i]  # 길이 11의 문자열을 지속적으로 만듬\n",
        "  sequences.append(seq)\n",
        "\n",
        "print('총 훈련 샘플의 수 : %d' %len(sequences))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 훈련 샘플의 수 : 426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShVSxjuUvkf8",
        "outputId": "d4a4bc50-6ee7-4cf2-cf8e-97f0a8f6933a"
      },
      "source": [
        "print(sequences)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I get on wi', ' get on wit', 'get on with', 'et on with ', 't on with l', ' on with li', 'on with lif', 'n with life', ' with life ', 'with life a', 'ith life as', 'th life as ', 'h life as a', ' life as a ', 'life as a p', 'ife as a pr', 'fe as a pro', 'e as a prog', ' as a progr', 'as a progra', 's a program', ' a programm', 'a programme', ' programmer', 'programmer,', 'rogrammer, ', 'ogrammer, I', 'grammer, I ', 'rammer, I l', 'ammer, I li', 'mmer, I lik', 'mer, I like', 'er, I like ', 'r, I like t', ', I like to', ' I like to ', 'I like to c', ' like to co', 'like to con', 'ike to cont', 'ke to conte', 'e to contem', ' to contemp', 'to contempl', 'o contempla', ' contemplat', 'contemplate', 'ontemplate ', 'ntemplate b', 'template be', 'emplate bee', 'mplate beer', 'plate beer.', 'late beer. ', 'ate beer. B', 'te beer. Bu', 'e beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sta', 'when I star', 'hen I start', 'en I start ', 'n I start t', ' I start to', 'I start to ', ' start to d', 'start to da', 'tart to day', 'art to dayd', 'rt to daydr', 't to daydre', ' to daydrea', 'to daydream', 'o daydream,', ' daydream, ', 'daydream, M', 'aydream, My', 'ydream, My ', 'dream, My m', 'ream, My mi', 'eam, My min', 'am, My mind', 'm, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. D', 'to wine. Do', 'o wine. Do ', ' wine. Do I', 'wine. Do I ', 'ine. Do I l', 'ne. Do I lo', 'e. Do I lov', '. Do I love', ' Do I love ', 'Do I love w', 'o I love wi', ' I love win', 'I love wine', ' love wine ', 'love wine m', 'ove wine mo', 've wine mor', 'e wine more', ' wine more ', 'wine more t', 'ine more th', 'ne more tha', 'e more than', ' more than ', 'more than b', 'ore than be', 're than bee', 'e than beer', ' than beer?', 'than beer? ', 'han beer? I', 'an beer? I ', 'n beer? I l', ' beer? I li', 'beer? I lik', 'eer? I like', 'er? I like ', 'r? I like t', '? I like to', ' I like to ', 'I like to u', ' like to us', 'like to use', 'ike to use ', 'ke to use w', 'e to use wo', ' to use wor', 'to use word', 'o use words', ' use words ', 'use words a', 'se words ab', 'e words abo', ' words abou', 'words about', 'ords about ', 'rds about b', 'ds about be', 's about bee', ' about beer', 'about beer.', 'bout beer. ', 'out beer. B', 'ut beer. Bu', 't beer. But', ' beer. But ', 'beer. But w', 'eer. But wh', 'er. But whe', 'r. But when', '. But when ', ' But when I', 'But when I ', 'ut when I s', 't when I st', ' when I sto', 'when I stop', 'hen I stop ', 'en I stop m', 'n I stop my', ' I stop my ', 'I stop my t', ' stop my ta', 'stop my tal', 'top my talk', 'op my talki', 'p my talkin', ' my talking', 'my talking,', 'y talking, ', ' talking, M', 'talking, My', 'alking, My ', 'lking, My m', 'king, My mi', 'ing, My min', 'ng, My mind', 'g, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine', 'ht to wine.', 't to wine. ', ' to wine. I', 'to wine. I ', 'o wine. I h', ' wine. I ha', 'wine. I hat', 'ine. I hate', 'ne. I hate ', 'e. I hate b', '. I hate bu', ' I hate bug', 'I hate bugs', ' hate bugs ', 'hate bugs a', 'ate bugs an', 'te bugs and', 'e bugs and ', ' bugs and e', 'bugs and er', 'ugs and err', 'gs and erro', 's and error', ' and errors', 'and errors.', 'nd errors. ', 'd errors. B', ' errors. Bu', 'errors. But', 'rrors. But ', 'rors. But I', 'ors. But I ', 'rs. But I j', 's. But I ju', '. But I jus', ' But I just', 'But I just ', 'ut I just t', 't I just th', ' I just thi', 'I just thin', ' just think', 'just think ', 'ust think b', 'st think ba', 't think bac', ' think back', 'think back ', 'hink back t', 'ink back to', 'nk back to ', 'k back to w', ' back to wi', 'back to win', 'ack to wine', 'ck to wine,', 'k to wine, ', ' to wine, A', 'to wine, An', 'o wine, And', ' wine, And ', 'wine, And I', \"ine, And I'\", \"ne, And I'm\", \"e, And I'm \", \", And I'm h\", \" And I'm ha\", \"And I'm hap\", \"nd I'm happ\", \"d I'm happy\", \" I'm happy \", \"I'm happy o\", \"'m happy on\", 'm happy onc', ' happy once', 'happy once ', 'appy once a', 'ppy once ag', 'py once aga', 'y once agai', ' once again', 'once again.', 'nce again. ', 'ce again. I', 'e again. I ', ' again. I l', 'again. I li', 'gain. I lik', 'ain. I like', 'in. I like ', 'n. I like t', '. I like to', ' I like to ', 'I like to h', ' like to ha', 'like to han', 'ike to hang', 'ke to hang ', 'e to hang o', ' to hang ou', 'to hang out', 'o hang out ', ' hang out w', 'hang out wi', 'ang out wit', 'ng out with', 'g out with ', ' out with p', 'out with pr', 'ut with pro', 't with prog', ' with progr', 'with progra', 'ith program', 'th programm', 'h programmi', ' programmin', 'programming', 'rogramming ', 'ogramming a', 'gramming an', 'ramming and', 'amming and ', 'mming and d', 'ming and de', 'ing and dee', 'ng and deep', 'g and deep ', ' and deep l', 'and deep le', 'nd deep lea', 'd deep lear', ' deep learn', 'deep learni', 'eep learnin', 'ep learning', 'p learning.', ' learning. ', 'learning. B', 'earning. Bu', 'arning. But', 'rning. But ', 'ning. But w', 'ing. But wh', 'ng. But whe', 'g. But when', '. But when ', ' But when l', 'But when le', 'ut when lef', 't when left', ' when left ', 'when left a', 'hen left al', 'en left alo', 'n left alon', ' left alone', 'left alone,', 'eft alone, ', 'ft alone, M', 't alone, My', ' alone, My ', 'alone, My m', 'lone, My mi', 'one, My min', 'ne, My mind', 'e, My mind ', ', My mind t', ' My mind tu', 'My mind tur', 'y mind turn', ' mind turns', 'mind turns ', 'ind turns s', 'nd turns st', 'd turns str', ' turns stra', 'turns strai', 'urns straig', 'rns straigh', 'ns straight', 's straight ', ' straight t', 'straight to', 'traight to ', 'raight to w', 'aight to wi', 'ight to win', 'ght to wine']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeHrBzCuvoSK"
      },
      "source": [
        "x = []\n",
        "for line in sequences:   # 전체 데이터에서 문장 샘플을 1개씩 꺼냄\n",
        "  temp_x = [char_to_index[char] for char in line]  # 문장 샘플에서 각 글자에 대해서 정수 인코딩 수행\n",
        "  x.append(temp_x)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D40vP2nIwHBf",
        "outputId": "c62a0aaa-325f-4ff9-edac-0340367cd2d7"
      },
      "source": [
        "for line in x[:5]:\n",
        "  print(line)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8, 0, 16, 14, 28, 0, 24, 23, 0, 31, 18]\n",
            "[0, 16, 14, 28, 0, 24, 23, 0, 31, 18, 28]\n",
            "[16, 14, 28, 0, 24, 23, 0, 31, 18, 28, 17]\n",
            "[14, 28, 0, 24, 23, 0, 31, 18, 28, 17, 0]\n",
            "[28, 0, 24, 23, 0, 31, 18, 28, 17, 0, 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hEbdcm_SwJDB"
      },
      "source": [
        "sequences = np.array(x)\n",
        "x = sequences[:,:-1]\n",
        "y = sequences[:,-1] # 맨 마지막 위치의 글자를 분리"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ild8WFKEwg5z",
        "outputId": "990291f6-92a0-4325-9502-da020654f4f2"
      },
      "source": [
        "for line in x[:5]:\n",
        "  print(line)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 8  0 16 14 28  0 24 23  0 31]\n",
            "[ 0 16 14 28  0 24 23  0 31 18]\n",
            "[16 14 28  0 24 23  0 31 18 28]\n",
            "[14 28  0 24 23  0 31 18 28 17]\n",
            "[28  0 24 23  0 31 18 28 17  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQgcJsAFwl4U",
        "outputId": "d9bfe102-c98d-4ae9-b56e-a7612e057458"
      },
      "source": [
        "print(y[:5])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[18 28 17  0 21]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RJ6AYbDwn16"
      },
      "source": [
        "### 원-핫 인코딩 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Vgi1RTBwx6g"
      },
      "source": [
        "sequences = [to_categorical(x, num_classes=vocab_size) for x in x]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKQeFIk2w5en"
      },
      "source": [
        "x = np.array(sequences)\n",
        "y = to_categorical(y,num_classes=vocab_size)  # y 에대한 원-핫 인코딩"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVTnpRI1xBjy",
        "outputId": "fb1a479e-07dd-4e9d-e976-a037f4f4ea29"
      },
      "source": [
        "print(x.shape)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(426, 10, 33)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeSz0tAhxB-8"
      },
      "source": [
        "- 샘플의 수 426  \n",
        "- 입력시퀀스의 길이 10  \n",
        "- 각 벡터의 차원 33  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lY-9I-KKy9Qd"
      },
      "source": [
        "### 모델 설계"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A01YhOc8y_SX"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-sjHtJEzAau"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(x.shape[1], x.shape[2])))\n",
        "model.add(Dense(vocab_size, activation='softmax'))"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgjEmfsczBQ-",
        "outputId": "a2f9430f-3fd0-4e1c-eab4-4b282466610e"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])\n",
        "model.fit(x, y, epochs=100, verbose=1)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/14 [==============================] - 2s 4ms/step - loss: 3.4449 - accuracy: 0.1620\n",
            "Epoch 2/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.1919 - accuracy: 0.1972\n",
            "Epoch 3/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 3.0047 - accuracy: 0.1972\n",
            "Epoch 4/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9627 - accuracy: 0.1972\n",
            "Epoch 5/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9322 - accuracy: 0.1972\n",
            "Epoch 6/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.9079 - accuracy: 0.1972\n",
            "Epoch 7/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8845 - accuracy: 0.1972\n",
            "Epoch 8/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.8583 - accuracy: 0.1972\n",
            "Epoch 9/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.8145 - accuracy: 0.2066\n",
            "Epoch 10/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.7709 - accuracy: 0.1995\n",
            "Epoch 11/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.7090 - accuracy: 0.2066\n",
            "Epoch 12/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.6515 - accuracy: 0.2371\n",
            "Epoch 13/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.5569 - accuracy: 0.2418\n",
            "Epoch 14/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.4954 - accuracy: 0.2746\n",
            "Epoch 15/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.4211 - accuracy: 0.2958\n",
            "Epoch 16/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.3475 - accuracy: 0.3451\n",
            "Epoch 17/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.2860 - accuracy: 0.3404\n",
            "Epoch 18/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.2016 - accuracy: 0.3498\n",
            "Epoch 19/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.1203 - accuracy: 0.3967\n",
            "Epoch 20/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 2.1226 - accuracy: 0.3521\n",
            "Epoch 21/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 2.0320 - accuracy: 0.4155\n",
            "Epoch 22/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.9641 - accuracy: 0.3991\n",
            "Epoch 23/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.9031 - accuracy: 0.4413\n",
            "Epoch 24/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.8378 - accuracy: 0.4366\n",
            "Epoch 25/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.7781 - accuracy: 0.4930\n",
            "Epoch 26/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.6879 - accuracy: 0.5235\n",
            "Epoch 27/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.6438 - accuracy: 0.5352\n",
            "Epoch 28/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5958 - accuracy: 0.5540\n",
            "Epoch 29/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.5469\n",
            "Epoch 30/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4643 - accuracy: 0.6080\n",
            "Epoch 31/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.4210 - accuracy: 0.5939\n",
            "Epoch 32/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 1.3542 - accuracy: 0.6080\n",
            "Epoch 33/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.3010 - accuracy: 0.6432\n",
            "Epoch 34/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1946 - accuracy: 0.6948\n",
            "Epoch 35/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.1520 - accuracy: 0.7136\n",
            "Epoch 36/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0894 - accuracy: 0.7160\n",
            "Epoch 37/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0566 - accuracy: 0.7465\n",
            "Epoch 38/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 1.0001 - accuracy: 0.7512\n",
            "Epoch 39/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.9403 - accuracy: 0.7676\n",
            "Epoch 40/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.9002 - accuracy: 0.7746\n",
            "Epoch 41/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.8408 - accuracy: 0.7981\n",
            "Epoch 42/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.7758 - accuracy: 0.8380\n",
            "Epoch 43/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.7291 - accuracy: 0.8545\n",
            "Epoch 44/100\n",
            "14/14 [==============================] - 0s 6ms/step - loss: 0.7352 - accuracy: 0.8380\n",
            "Epoch 45/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6836 - accuracy: 0.8638\n",
            "Epoch 46/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.6335 - accuracy: 0.8709\n",
            "Epoch 47/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5801 - accuracy: 0.9038\n",
            "Epoch 48/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.5522 - accuracy: 0.9014\n",
            "Epoch 49/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.5173 - accuracy: 0.9108\n",
            "Epoch 50/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.9296\n",
            "Epoch 51/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.9366\n",
            "Epoch 52/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.9319\n",
            "Epoch 53/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.4042 - accuracy: 0.9554\n",
            "Epoch 54/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3680 - accuracy: 0.9577\n",
            "Epoch 55/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.3490 - accuracy: 0.9601\n",
            "Epoch 56/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3264 - accuracy: 0.9624\n",
            "Epoch 57/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.3011 - accuracy: 0.9742\n",
            "Epoch 58/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2915 - accuracy: 0.9648\n",
            "Epoch 59/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2735 - accuracy: 0.9695\n",
            "Epoch 60/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2675 - accuracy: 0.9765\n",
            "Epoch 61/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.9742\n",
            "Epoch 62/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2428 - accuracy: 0.9718\n",
            "Epoch 63/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2256 - accuracy: 0.9765\n",
            "Epoch 64/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.2258 - accuracy: 0.9718\n",
            "Epoch 65/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.2041 - accuracy: 0.9765\n",
            "Epoch 66/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9812\n",
            "Epoch 67/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1866 - accuracy: 0.9695\n",
            "Epoch 68/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1768 - accuracy: 0.9812\n",
            "Epoch 69/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1700 - accuracy: 0.9765\n",
            "Epoch 70/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1616 - accuracy: 0.9718\n",
            "Epoch 71/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1504 - accuracy: 0.9812\n",
            "Epoch 72/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1464 - accuracy: 0.9765\n",
            "Epoch 73/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1465 - accuracy: 0.9742\n",
            "Epoch 74/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1377 - accuracy: 0.9789\n",
            "Epoch 75/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1307 - accuracy: 0.9812\n",
            "Epoch 76/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1294 - accuracy: 0.9812\n",
            "Epoch 77/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1249 - accuracy: 0.9789\n",
            "Epoch 78/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1211 - accuracy: 0.9812\n",
            "Epoch 79/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1161 - accuracy: 0.9765\n",
            "Epoch 80/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9789\n",
            "Epoch 81/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1170 - accuracy: 0.9765\n",
            "Epoch 82/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1164 - accuracy: 0.9789\n",
            "Epoch 83/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.1115 - accuracy: 0.9742\n",
            "Epoch 84/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1056 - accuracy: 0.9789\n",
            "Epoch 85/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0989 - accuracy: 0.9836\n",
            "Epoch 86/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0997 - accuracy: 0.9765\n",
            "Epoch 87/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1090 - accuracy: 0.9836\n",
            "Epoch 88/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9812\n",
            "Epoch 89/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0969 - accuracy: 0.9812\n",
            "Epoch 90/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9836\n",
            "Epoch 91/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9789\n",
            "Epoch 92/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0864 - accuracy: 0.9836\n",
            "Epoch 93/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9836\n",
            "Epoch 94/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0809 - accuracy: 0.9836\n",
            "Epoch 95/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9812\n",
            "Epoch 96/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9836\n",
            "Epoch 97/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0785 - accuracy: 0.9812\n",
            "Epoch 98/100\n",
            "14/14 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9742\n",
            "Epoch 99/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0743 - accuracy: 0.9812\n",
            "Epoch 100/100\n",
            "14/14 [==============================] - 0s 4ms/step - loss: 0.0715 - accuracy: 0.9812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3d3a3a59d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6W8CWhzzW-x"
      },
      "source": [
        "def sentence_generation(model, char_to_index, seq_length, seed_text, n):\n",
        "  # 모델, 인덱스 정보, 문장 길이, 초기 시퀀스, 반복 횟수\n",
        "\n",
        "  init_text = seed_text #문장 생성에 사용할 초기 시퀀스\n",
        "  sentence = ''\n",
        "\n",
        "  for _ in range(n): # n번 반복\n",
        "    encoded = [char_to_index[char] for char in seed_text] #현재 시퀀스에 대한 정수 인코딩\n",
        "    encoded = pad_sequences([encoded], maxlen=seq_length, padding='pre') #데이터에 대한 패딩\n",
        "    encoded = to_categorical(encoded, num_classes=len(char_to_index))\n",
        "    result = model.predict_classes(encoded, verbose=0)\n",
        "    #입력한 x(현재 시퀀스)에 대해서 y를 예측하고 y(예측한 글자)를 result에 저장\n",
        "\n",
        "    for char, index in char_to_index.items(): #만약 예측한 글자와 인덱스와 동일한 글자가 있다면\n",
        "      if index == result: #해당 글자가 예측 글자이므로 break\n",
        "        break\n",
        "    \n",
        "    seed_text = seed_text + char # 현재 시퀀스 + 예측 글자를 현재 시퀀스에 변경\n",
        "    sentence = sentence + char # 예측 글자를 문장에 저장\n",
        "\n",
        "  sentence = init_text + sentence\n",
        "  return sentence"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hD5Ei_F31K0R",
        "outputId": "61cc1a89-c725-414a-b77b-21e861636565"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'I get on w', 100))"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "I get on with life as a programmer, I like to use words about beer. But when I start to daydream, My mind turn\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yaq1bos71UTq",
        "outputId": "a67d1fdb-59cc-4e73-af25-2043fbaf41e7"
      },
      "source": [
        "print(sentence_generation(model, char_to_index, 10, 'Do I love wine', 100))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Do I love wine more than beer? I like to use words about beer. But when I start to daydream, My mind turns straigh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLymZRwmXTeV"
      },
      "source": [
        "## 네이버 쇼핑 리뷰 감성 분석\n",
        "- 총 200,000ro 리뷰로 구성  \n",
        "- 평점이 5점 만점에 1, 2, 4, 5인 리뷰들로 구성\n",
        "- 평점이 4, 5인 리뷰들에 긍정 1, 부정 0\n",
        "- 감성 분류 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yVB2eDklXYN3",
        "outputId": "16341a2d-2d6d-47d8-e1ba-3fe13ab546e4"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "# mecab"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8S3SD_WXael",
        "outputId": "e8bb5fa7-b03d-4ff3-a9c1-ef15d694e442"
      },
      "source": [
        "!pwd "
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnbl-54iYQZi",
        "outputId": "d57586a6-9050-4067-fa24-4d1284925a56"
      },
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVhjFJ1LYRss",
        "outputId": "71ffb6a3-9a50-4c35-9306-381d5ba91008"
      },
      "source": [
        "ls"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mimages\u001b[0m/                                    LICENSE\n",
            "install_mecab-ko_on_colab190912.sh         README.md\n",
            "install_mecab-ko_on_colab_light_210108.sh\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3nf64jwYSq1",
        "outputId": "f530ef4f-dc3b-47aa-fcfc-4858e742cc92"
      },
      "source": [
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 60.2MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.1MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-17 13:58:54--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=HfIkqA1zctPViu2MDcxZD2Befk8%3D&Expires=1623939561&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 13:58:55--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=HfIkqA1zctPViu2MDcxZD2Befk8%3D&Expires=1623939561&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.138.209\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.138.209|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-06-17 13:58:55 (33.7 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-17 14:00:15--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 18.205.93.2, 18.205.93.0, 18.205.93.1, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|18.205.93.2|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=bn3bcCNiSZkBty6BWwXgDkMaVbQ%3D&Expires=1623940067&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-17 14:00:15--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=bn3bcCNiSZkBty6BWwXgDkMaVbQ%3D&Expires=1623940067&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.133.193\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.133.193|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   101MB/s    in 0.5s    \n",
            "\n",
            "2021-06-17 14:00:16 (101 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4Pn6mZFZN5P"
      },
      "source": [
        "from konlpy.tag import Mecab"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zYSh0afYT30",
        "outputId": "013750b0-c715-4cab-de39-fdc42282a1ec"
      },
      "source": [
        "mecab = Mecab() # mecab 테스트중\n",
        "print(mecab.morphs('오늘 너무 피곤하고 몸도 아프고 제정신이 아니네 ㅠㅠ'))"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['오늘', '너무', '피곤', '하', '고', '몸', '도', '아프', '고', '제정신', '이', '아니', '네', 'ㅠㅠ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xy4aMqCxZL-F"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import urllib.request\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrxEseGPcC6I"
      },
      "source": [
        "\n",
        "### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce22eGJecHLE",
        "outputId": "eae660d0-6256-4eb1-cb99-d58f047efea1"
      },
      "source": [
        "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/bab2min/corpus/master/sentiment/naver_shopping.txt\", filename=\"ratings_total.txt\")"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ratings_total.txt', <http.client.HTTPMessage at 0x7f3d16341f50>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7JFPRapcIm5"
      },
      "source": [
        "total_data = pd.read_table('ratings_total.txt', names=['ratings', 'reviews'])"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwNxvogDcJv_",
        "outputId": "3971780b-ff4a-4519-9e37-dd4beb9e31fe"
      },
      "source": [
        "print('전체 리뷰 갯수 :', len(total_data))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 리뷰 갯수 : 200000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "KEMz9OBIcKo4",
        "outputId": "db85af36-8bb2-41c9-f255-e45d1881c85f"
      },
      "source": [
        "total_data[:5]"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews\n",
              "0        5                                            배공빠르고 굿\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkMMiBa_cLnd"
      },
      "source": [
        "### 훈련 데이터와 테스트 데이터를 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "eah4xccMcN_G",
        "outputId": "34bb07b4-4e8a-4543-bd8e-e8822911c7ea"
      },
      "source": [
        "total_data['label'] = np.select([total_data.ratings > 3], [1], default=0)\n",
        "total_data[:5]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ratings</th>\n",
              "      <th>reviews</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ratings                                            reviews  label\n",
              "0        5                                            배공빠르고 굿      1\n",
              "1        2                      택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0\n",
              "2        5  아주좋아요 바지 정말 좋아서2개 더 구매했어요 이가격에 대박입니다. 바느질이 조금 ...      1\n",
              "3        2  선물용으로 빨리 받아서 전달했어야 하는 상품이었는데 머그컵만 와서 당황했습니다. 전...      0\n",
              "4        5                  민트색상 예뻐요. 옆 손잡이는 거는 용도로도 사용되네요 ㅎㅎ      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nnTmO2vcO-z",
        "outputId": "5cde308d-ecde-4e24-dac3-2afcb509d1bf"
      },
      "source": [
        "# 각 열에 중복을 제외한 샘플의 수를 카운트\n",
        "total_data['ratings'].nunique(), total_data['reviews'].nunique(), total_data['label'].nunique()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4, 199908, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaJd5SmzcP9G",
        "outputId": "e54770a4-dc3d-46a0-85b4-7920c444cd92"
      },
      "source": [
        "total_data.drop_duplicates(subset=['reviews'], inplace=True) #reviews열에서 중복인 내용이 있다면 중복 제거\n",
        "print('총 샘플의 수 : ',len(total_data))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "총 샘플의 수 :  199908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ti6GReUcRGg",
        "outputId": "0a71b3c3-a719-464f-f30e-b935d8dbee59"
      },
      "source": [
        "# NULL값 유무\n",
        "print(total_data.isnull().values.any())"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SoicleScXWh",
        "outputId": "af52856a-d194-4839-e2c2-b5a71acf391d"
      },
      "source": [
        "# 훈련데이터와 테스트 데이터 3:1비율로 나눔\n",
        "train_data, test_data = train_test_split(total_data, test_size = 0.25, random_state=42)\n",
        "print('훈련용 리뷰의 갯수 : ', len(train_data))\n",
        "print('테스트용 리뷰의 갯수 : ', len(test_data))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰의 갯수 :  149931\n",
            "테스트용 리뷰의 갯수 :  49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9G3HklkscYK-"
      },
      "source": [
        "## 레이블의 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "BOBT1C02cZ4i",
        "outputId": "c2075164-5d0b-4bc2-f6b4-e578afd54f51"
      },
      "source": [
        "train_data['label'].value_counts().plot(kind='bar')"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f3cd7219a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOSh8hhLchot",
        "outputId": "06309662-44b8-40d5-a51d-051bbc88a5c7"
      },
      "source": [
        "print(train_data.groupby('label').size().reset_index(name='count'))"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   label  count\n",
            "0      0  74918\n",
            "1      1  75013\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha-K0e3acoWu"
      },
      "source": [
        "## 데이터 정제하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqc1m0Dlcvtw"
      },
      "source": [
        "정규표현식을 사용하여 한글을 제외하고 모두 제거\n",
        "\n",
        "빈 샘플이 생겼는지 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pHQCSL5c1aM",
        "outputId": "e6e677c7-8d09-4622-9c51-a36456b5a682"
      },
      "source": [
        "train_data['reviews'] = train_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "train_data['reviews'].replace('', np.nan, inplace=True)\n",
        "print(train_data.isnull().sum())"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ratings    0\n",
            "reviews    0\n",
            "label      0\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPcl-uNIjEBx",
        "outputId": "573fcf5e-9835-4315-dad3-c0f78322b1fa"
      },
      "source": [
        "test_data.drop_duplicates(subset=['reviews'], inplace=True)\n",
        "test_data['reviews'] = test_data['reviews'].str.replace(\"[^ㄱ-ㅎ ㅏ-ㅣ 가-힣]\",\"\")\n",
        "test_data['reviews'].replace('', np.nan, inplace=True)\n",
        "test_data = test_data.dropna(how='any')\n",
        "print('전처리 후 테스트용 샘플의 갯수 : ',len(test_data))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  method=method,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "전처리 후 테스트용 샘플의 갯수 :  49977\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKVNeQZQliNm"
      },
      "source": [
        "### 토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6XwIj5ZlkZ4",
        "outputId": "34af210a-a428-4a34-b6fc-bc22b9d6e0ec"
      },
      "source": [
        "mecab = Mecab()\n",
        "print(mecab.morphs('이런 상품도 상품이라고 허허허'))"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['이런', '상품', '도', '상품', '이', '라고', '허허허']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEN2DPhXllo_"
      },
      "source": [
        "### 불용어 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cknT4H8flnlw"
      },
      "source": [
        "stopwords = ['도', '는', '다', '의', '가', '이', '은', '한', '에', '하', '고', '을', '를', '인', '듯', '과', '와', '네', '들', '듯', '지', '임', '게']"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd88izEOlogk",
        "outputId": "77447ac0-9a1c-4fe2-cc24-5351dda1a35d"
      },
      "source": [
        "train_data['tokenized'] = train_data['reviews'].apply(mecab.morphs)\n",
        "train_data['tokenized'] = train_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9txLzPN9lpeI"
      },
      "source": [
        "test_data['tokenized'] = test_data['reviews'].apply(mecab.morphs)\n",
        "test_data['tokenized'] = test_data['tokenized'].apply(lambda x: [item for item in x if item not in stopwords])"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z33eKTHOl2BM"
      },
      "source": [
        "### 단어와 길이 분포 확인하기\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_n645wDl5hG"
      },
      "source": [
        "negative_words = np.hstack(train_data[train_data.label == 0]['tokenized'].values)\n",
        "positive_words = np.hstack(train_data[train_data.label == 1]['tokenized'].values)\n"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpJ-B7hnl6r-",
        "outputId": "43b27bd9-fc57-4ef2-acd4-18de2a3cefc4"
      },
      "source": [
        "## 부정리뷰에 대해서 빈도가 높은 상위 20개 단어 출력. Counter()를 사용하여 각 단어에 대한 빈도수 계산\n",
        "negative_word_count = Counter(negative_words)\n",
        "print(negative_word_count.most_common(20))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('네요', 31799), ('는데', 20295), ('안', 19718), ('어요', 14849), ('있', 13200), ('너무', 13058), ('했', 11783), ('좋', 9812), ('배송', 9677), ('같', 8997), ('구매', 8876), ('어', 8869), ('거', 8854), ('없', 8670), ('아요', 8642), ('습니다', 8436), ('그냥', 8355), ('되', 8345), ('잘', 8029), ('않', 7984)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEOkdYU1l7x4",
        "outputId": "20ecc7ed-794e-4c90-b1ec-8a7d9346fb8d"
      },
      "source": [
        "positive_word_count = Counter(positive_words)\n",
        "print(positive_word_count.most_common(20))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('좋', 39488), ('아요', 21184), ('네요', 19895), ('어요', 18686), ('잘', 18602), ('구매', 16171), ('습니다', 13320), ('있', 12391), ('배송', 12275), ('는데', 11670), ('했', 9818), ('합니다', 9801), ('먹', 9635), ('재', 9273), ('너무', 8397), ('같', 7868), ('만족', 7261), ('거', 6482), ('어', 6294), ('쓰', 6292)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "l2sXTzhCl-I8",
        "outputId": "247ed698-7269-4f69-c328-69618614f76a"
      },
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
        "text_len = train_data[train_data['label']== 1]['tokenized'].map(lambda x: len(x))\n",
        "ax1.hist(text_len, color ='red')\n",
        "ax1.set_title('Positive Reviews')\n",
        "ax1.set_xlabel('length of samples')\n",
        "ax1.set_ylabel('number of samples')\n",
        "print('긍정 리뷰의 평균 길이 :',np.mean(text_len))\n",
        "\n",
        "text_len = train_data[train_data['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "ax2.hist(text_len, color='blue')\n",
        "ax2.set_title('Negative Reviews')\n",
        "fig.suptitle('Words in texts')\n",
        "ax2.set_xlabel('length of samples')\n",
        "ax2.set_ylabel('number of samples')\n",
        "print('부정 리뷰의 평균 길이 :', np.mean(text_len))\n",
        "plt.show()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "긍정 리뷰의 평균 길이 : 13.587751456414221\n",
            "부정 리뷰의 평균 길이 : 17.029512266744973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8hSRlA5mDDw"
      },
      "source": [
        "x_train = train_data['tokenized'].values\n",
        "y_train = train_data['label'].values\n",
        "x_test = test_data['tokenized'].values\n",
        "y_test = test_data['label'].values"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjK6_r5dmE8H"
      },
      "source": [
        "### 정수 인코딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fel8IdwTmHKv"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(x_train)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOisGbewmIGa",
        "outputId": "321ba3e4-e0b6-41cc-8ffd-5e3330d47d77"
      },
      "source": [
        "threshold = 2\n",
        "total_cnt = len(t.word_index) #단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어를 카운트\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
        "\n",
        "# 단어와 빈도수의 쌍을 key와 value로 받는다.\n",
        "for key, value in t.word_counts.items():\n",
        "  total_freq = total_freq + value\n",
        "\n",
        "  if (value < threshold):\n",
        "    rare_cnt = rare_cnt + 1\n",
        "    rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀단어의 수: %s '% (threshold-1, rare_cnt))\n",
        "print('단어 집합에서 희귀 단어의 비율 :', (rare_cnt/ total_cnt)*100)\n",
        "print('전체 등장 빈도에서 희귀단어 등장 빈도 비율: ',(rare_freq/total_freq)*100)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합(vocabulary)의 크기 : 39998\n",
            "등장 빈도가 1번 이하인 희귀단어의 수: 18213 \n",
            "단어 집합에서 희귀 단어의 비율 : 45.53477673883694\n",
            "전체 등장 빈도에서 희귀단어 등장 빈도 비율:  0.7935688376196857\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4opOrklImJIt",
        "outputId": "25d9b4af-9ff2-405d-e353-6b149b874ac7"
      },
      "source": [
        "# 전체 단어 갯수 중 빈도수 2이하인 단어 갯수는 제거\n",
        "# 0번 패딩 토큰고 1번 OOV토큰을 고려해서 +2\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :', vocab_size)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 21787\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNiLbT46mK9i",
        "outputId": "16551f81-fc63-4e94-ef40-9f05526d5cb0"
      },
      "source": [
        "original_vocab_size = vocab_size + rare_cnt -2\n",
        "print('원래 vocab size : ', original_vocab_size)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "원래 vocab size :  39998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGYLjO8MmMl9"
      },
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token='OOV')\n",
        "tokenizer.fit_on_texts(x_train)\n",
        "x_train = tokenizer.texts_to_sequences(x_train)\n",
        "x_test = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_o8a3yfYmOa9",
        "outputId": "04f60fb1-6c6d-44cb-ce5c-18da74a8470e"
      },
      "source": [
        "print(x_train[:3])\n",
        "print(x_test[:3])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[67, 2060, 299, 14259, 263, 73, 6, 236, 168, 137, 805, 2951, 625, 2, 77, 62, 207, 40, 1343, 155, 3, 6], [482, 409, 52, 8530, 2561, 2517, 339, 2918, 250, 2357, 38, 473, 2], [46, 24, 825, 105, 35, 2372, 160, 7, 10, 8061, 4, 1319, 29, 140, 322, 41, 59, 160, 140, 7, 1916, 2, 113, 162, 1379, 323, 119, 136]]\n",
            "[[14, 704, 767, 116, 186, 252, 12], [339, 3904, 62, 3816, 1651], [11, 69, 2, 49, 164, 3, 27, 15, 6, 513, 289, 17, 92, 110, 564, 59, 7, 2]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLtb3B2QmPwA"
      },
      "source": [
        "### 패딩"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        },
        "id": "74ZackDYmSBO",
        "outputId": "b3437619-1cd2-4fa2-cf49-0416d5e4ea03"
      },
      "source": [
        "print('리뷰의 최대 길이 :', max(len(l) for l in x_train))\n",
        "print('리뷰의 평균 길이 :', sum(map(len, x_train))/len(x_train))\n",
        "plt.hist([len(s) for s in x_train], bins=50)\n",
        "plt.xlabel('length of samples')\n",
        "plt.ylabel('number of samples')\n",
        "plt.show()"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "리뷰의 최대 길이 : 85\n",
            "리뷰의 평균 길이 : 15.307541469075774\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DjLW_pGmTNG"
      },
      "source": [
        "def below_threshold_len(max_len, nested_list):\n",
        "  cnt = 0\n",
        "  for s in nested_list:\n",
        "    if (len(s) <= max_len):\n",
        "      cnt = cnt + 1\n",
        "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율 : %s'%(max_len, (cnt/len(nested_list))*100))"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNGBHogvmUec",
        "outputId": "31aacc7a-33a3-41e5-fc36-66ab9fcc2a2d"
      },
      "source": [
        "max_len = 80\n",
        "below_threshold_len(max_len, x_train)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플 중 길이가 80 이하인 샘플의 비율 : 99.99933302652553\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHzn5HnBmVb7"
      },
      "source": [
        "x_train = pad_sequences(x_train, maxlen= max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9haj7jlpmWu9",
        "outputId": "0b85e46c-362f-4e85-f1db-05fff535367d"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149931, 80)\n",
            "(49977, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgn7_vFwmXxI"
      },
      "source": [
        "### GRU모델로 학습하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bJk7bxZmZo7"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYP_PlcemaoP"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, 100))\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kW9iYQgWmb2U"
      },
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXs0zq3dmcyy",
        "outputId": "227e5a31-1285-4917-e503-45c59f04cd34"
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "history = model.fit(x_train, y_train, epochs= 30, callbacks=[es, mc], batch_size = 60, validation_split=0.2)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2000/2000 [==============================] - 69s 34ms/step - loss: 0.2701 - acc: 0.8974 - val_loss: 0.2241 - val_acc: 0.9181\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.91810, saving model to best_model.h5\n",
            "Epoch 2/30\n",
            "2000/2000 [==============================] - 68s 34ms/step - loss: 0.1942 - acc: 0.9301 - val_loss: 0.2152 - val_acc: 0.9222\n",
            "\n",
            "Epoch 00002: val_acc improved from 0.91810 to 0.92217, saving model to best_model.h5\n",
            "Epoch 3/30\n",
            "2000/2000 [==============================] - 66s 33ms/step - loss: 0.1597 - acc: 0.9435 - val_loss: 0.2259 - val_acc: 0.9191\n",
            "\n",
            "Epoch 00003: val_acc did not improve from 0.92217\n",
            "Epoch 4/30\n",
            "2000/2000 [==============================] - 65s 32ms/step - loss: 0.1329 - acc: 0.9535 - val_loss: 0.2512 - val_acc: 0.9156\n",
            "\n",
            "Epoch 00004: val_acc did not improve from 0.92217\n",
            "Epoch 5/30\n",
            "2000/2000 [==============================] - 65s 33ms/step - loss: 0.1098 - acc: 0.9615 - val_loss: 0.2717 - val_acc: 0.9120\n",
            "\n",
            "Epoch 00005: val_acc did not improve from 0.92217\n",
            "Epoch 6/30\n",
            "2000/2000 [==============================] - 65s 33ms/step - loss: 0.0915 - acc: 0.9677 - val_loss: 0.3246 - val_acc: 0.9062\n",
            "\n",
            "Epoch 00006: val_acc did not improve from 0.92217\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1285iiRkmd6y",
        "outputId": "0615e427-ec45-41e6-ad85-d13b52b7955f"
      },
      "source": [
        "loaded_model = load_model('best_model.h5')\n",
        "print('\\n 테스트 정확도 : %.4f'% (loaded_model.evaluate(x_test, y_test)[1]))"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1562/1562 [==============================] - 7s 4ms/step - loss: 0.2202 - acc: 0.9210\n",
            "\n",
            " 테스트 정확도 : 0.9210\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5wLfJgrmgGB"
      },
      "source": [
        "### 리뷰 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uq9zxg4mhV9"
      },
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "  new_sentence = mecab.morphs(new_sentence) #토큰화\n",
        "  new_sentence = [word for word in new_sentence if not word in stopwords] #불용어 제거\n",
        "  encoded = tokenizer.texts_to_sequences([new_sentence])\n",
        "  pad_new = pad_sequences(encoded, maxlen=max_len) # 패딩\n",
        "\n",
        "  score = float(loaded_model.predict(pad_new)) #d예측\n",
        "\n",
        "  if (score >0.5):\n",
        "    print('{:.2f}%확률로 긍정 리뷰입니다. '.format(score*100))\n",
        "  else:\n",
        "    print('{:.2f}%확률로 부정 리뷰입니다. '.format((1-score)*100))\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dbzvlp6Gmk5C",
        "outputId": "f6348844-22ef-4751-b864-fbfc39723af4"
      },
      "source": [
        "sentiment_predict('이 상품 진짜 좋아요.. 저는 강추 대박')"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "96.76%확률로 긍정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RT_tH-rummz0",
        "outputId": "edd8dd6e-0999-498c-be29-5b5b6d5ed43c"
      },
      "source": [
        "sentiment_predict('이 상품 별로에요..')"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.37%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltm6HsfJmmxi",
        "outputId": "d61ef0ff-e9c2-42d1-c432-1720eb30d115"
      },
      "source": [
        "sentiment_predict('진짜 배송 늦고 개별로 개짜증')"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.38%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFfmjIHYmmuv",
        "outputId": "a72bbe0a-d7ea-4a8a-ee5e-ecbfa8df760a"
      },
      "source": [
        "sentiment_predict('그냥 그래요')"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.41%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ruy64SpimmsI",
        "outputId": "6e214cc2-6f1e-4566-d3ba-e8103ec72e34"
      },
      "source": [
        "sentiment_predict('ㄴㅇㄹㄴㅇㄹㄴㅇㄹㄴㅇㄹㅇㄴ귀찮아')"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "71.79%확률로 부정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlf8M7jjmmmH",
        "outputId": "beb74865-fe5e-4590-ae9f-171c4336236d"
      },
      "source": [
        "sentiment_predict('너무 짱이에요')"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.36%확률로 긍정 리뷰입니다. \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAz0NIS9mmcB"
      },
      "source": [
        "## 글자 단위(Character-level)로 구현한 seq2seq 번역기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2FLt3pnmt1V",
        "outputId": "72330612-7c10-418f-a406-08e0ddb9a166"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEtJ_QJEmvIJ",
        "outputId": "ddf4a722-794f-41c8-f4b9-983d87191127"
      },
      "source": [
        "cd ../"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETiEakdemycy"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "0V_l_r5EmyaB",
        "outputId": "d9237ace-6067-4a07-c005-67992769dc4d"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "file_path = '/content/drive/MyDrive/dataset/fra.txt'\n",
        "lines = pd.read_csv(file_path, names=['eng', 'fra', 'cc'], sep='\\t')\n",
        "lines.sample(5)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "      <th>cc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14465</th>\n",
              "      <td>It looked funny.</td>\n",
              "      <td>Ça avait l'air amusant.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66297</th>\n",
              "      <td>You won't be interested.</td>\n",
              "      <td>Vous ne serez pas intéressées.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188255</th>\n",
              "      <td>After spending hours out in the cold winter wi...</td>\n",
              "      <td>Après avoir passé des heures au dehors dans le...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158631</th>\n",
              "      <td>I should've known something was going on.</td>\n",
              "      <td>J'aurais dû savoir qu'il se passait quelque ch...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60246</th>\n",
              "      <td>Everyone knows his name.</td>\n",
              "      <td>Tout le monde connaît son nom.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      eng  ...                                                 cc\n",
              "14465                                    It looked funny.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "66297                            You won't be interested.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "188255  After spending hours out in the cold winter wi...  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "158631          I should've known something was going on.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "60246                            Everyone knows his name.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "eLe4nldomyXv",
        "outputId": "0b0c3311-f3a0-48d7-8ff5-ebef12544adc"
      },
      "source": [
        "lines = lines[['eng', 'fra']][:50000] #5만개 샘플사용\n",
        "lines.sample(5)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1546</th>\n",
              "      <td>Well done!</td>\n",
              "      <td>Bravo !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26643</th>\n",
              "      <td>Will you be going?</td>\n",
              "      <td>Irez-vous ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45630</th>\n",
              "      <td>You're very generous.</td>\n",
              "      <td>Vous êtes très généreuse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49315</th>\n",
              "      <td>It's the best we have.</td>\n",
              "      <td>C'est le meilleur que nous avons.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28719</th>\n",
              "      <td>I have no religion.</td>\n",
              "      <td>Je n'ai pas de religion.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          eng                                fra\n",
              "1546               Well done!                            Bravo !\n",
              "26643      Will you be going?                        Irez-vous ?\n",
              "45630   You're very generous.          Vous êtes très généreuse.\n",
              "49315  It's the best we have.  C'est le meilleur que nous avons.\n",
              "28719     I have no religion.           Je n'ai pas de religion."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "3H2OMjNsmyVW",
        "outputId": "7a61149c-bf63-463a-a129-fc0168951f52"
      },
      "source": [
        "# 시작토큰과 종료 토큰 추가\n",
        "sos_token = '\\t'\n",
        "eos_token = '\\n'\n",
        "lines.fra = lines.fra.apply(lambda x: '\\t' + x + '\\n')\n",
        "print('전체 샘플의 수 :',len(lines))\n",
        "lines.sample(5)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>fra</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15198</th>\n",
              "      <td>That's old news.</td>\n",
              "      <td>\\tOn le sait déjà.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34185</th>\n",
              "      <td>How is that spelled?</td>\n",
              "      <td>\\tComment l'écrit-on ?\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6073</th>\n",
              "      <td>We're at war.</td>\n",
              "      <td>\\tNous sommes en guerre.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33803</th>\n",
              "      <td>He drinks to excess.</td>\n",
              "      <td>\\tIl boit trop d'alcool.\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6900</th>\n",
              "      <td>I can do this.</td>\n",
              "      <td>\\tJe peux le faire !\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        eng                         fra\n",
              "15198      That's old news.        \\tOn le sait déjà.\\n\n",
              "34185  How is that spelled?    \\tComment l'écrit-on ?\\n\n",
              "6073          We're at war.  \\tNous sommes en guerre.\\n\n",
              "33803  He drinks to excess.  \\tIl boit trop d'alcool.\\n\n",
              "6900         I can do this.      \\tJe peux le faire !\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lKy-BS0mySh",
        "outputId": "1b154393-8fd0-499e-8d57-c446ded33456"
      },
      "source": [
        "eng_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "eng_tokenizer.fit_on_texts(lines.eng)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "input_text = eng_tokenizer.texts_to_sequences(lines.eng)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "input_text[:3]"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[19, 3, 8], [19, 3, 8], [19, 3, 8]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dTlkoMzomyP3",
        "outputId": "efae7c97-821f-4043-fd2f-ad4b359c56ca"
      },
      "source": [
        "fra_tokenizer = Tokenizer(char_level=True)\n",
        "# 글자 단위로 토큰화\n",
        "fra_tokenizer.fit_on_texts(lines.fra)\n",
        "# 50000개의 행을 가진 eng의 각 행에 토큰화 수행\n",
        "target_text = fra_tokenizer.texts_to_sequences(lines.fra)\n",
        "# 단어를 숫자값 인덱스로 변환하여 저장\n",
        "target_text[:3]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[10, 19, 5, 1, 31, 11],\n",
              " [10, 15, 5, 12, 16, 29, 2, 14, 11],\n",
              " [10, 26, 9, 8, 28, 2, 1, 31, 11]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3maVvilemyNB",
        "outputId": "8c919902-1b83-4f6b-9607-15e38333317d"
      },
      "source": [
        "eng_vocab_size = len(eng_tokenizer.word_index) + 1\n",
        "fra_vocab_size = len(fra_tokenizer.word_index) + 1\n",
        "print('영어 단어장의 크기 :',eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기 :', fra_vocab_size)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 단어장의 크기 : 52\n",
            "프랑스어 단어장의 크기 : 73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XR58DclAmyK1",
        "outputId": "b116f814-3f25-469a-edb7-19e814669b8e"
      },
      "source": [
        "max_eng_seq_len = max([len(line) for line in input_text])\n",
        "max_fra_seq_len = max([len(line) for line in target_text])\n",
        "\n",
        "print('영어 시퀀스의 최대 길이', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 시퀀스의 최대 길이 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvQ1MHCUmyH_",
        "outputId": "61743636-5b4e-46ce-b7b1-d5cc44487be1"
      },
      "source": [
        "print('전체 샘플의 수 :', len(lines))\n",
        "print('영어 단어장의 크기:', eng_vocab_size)\n",
        "print('프랑스어 단어장의 크기:', fra_vocab_size)\n",
        "print('영어 시퀀스의 최대 길이:', max_eng_seq_len)\n",
        "print('프랑스 시퀀스의 최대 길이', max_fra_seq_len)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 샘플의 수 : 50000\n",
            "영어 단어장의 크기: 52\n",
            "프랑스어 단어장의 크기: 73\n",
            "영어 시퀀스의 최대 길이: 22\n",
            "프랑스 시퀀스의 최대 길이 74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5JHf0FFmyFZ"
      },
      "source": [
        "encoder_input = input_text\n",
        "\n",
        "# 종료 토큰 제거\n",
        "decoder_input = [[char for char in line if char != fra_tokenizer.word_index[eos_token]] for line in target_text]\n",
        "# 시작 토큰 제거\n",
        "decoder_target = [[char for char in line if char != fra_tokenizer.word_index[sos_token]] for line in target_text]\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWpI2aWim89e",
        "outputId": "446ed162-fa4b-4d76-a33f-17379947cce6"
      },
      "source": [
        "print(decoder_input[:3]) # <eos>토큰 제거\n",
        "print(decoder_target[:3]) # <sos>토큰 제거"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[10, 19, 5, 1, 31], [10, 15, 5, 12, 16, 29, 2, 14], [10, 26, 9, 8, 28, 2, 1, 31]]\n",
            "[[19, 5, 1, 31, 11], [15, 5, 12, 16, 29, 2, 14, 11], [26, 9, 8, 28, 2, 1, 31, 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE07T4uCm869",
        "outputId": "5dd630c6-ba20-4ab8-80e4-8a6edf6df038"
      },
      "source": [
        "encoder_input = pad_sequences(encoder_input, maxlen=max_eng_seq_len, padding='post')\n",
        "decoder_input = pad_sequences(decoder_input, maxlen=max_fra_seq_len, padding='post')\n",
        "decoder_target = pad_sequences(decoder_target, maxlen=max_fra_seq_len, padding='post')\n",
        "\n",
        "print('영어 데이터의 크기(shape) :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 : ', np.shape(decoder_target))"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기(shape) : (50000, 22)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74)\n",
            "프랑스어 출력데이터의 크기 :  (50000, 74)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXFV_Prmm837",
        "outputId": "6edf5b0b-53b5-4c6f-ebcc-e44466be87d5"
      },
      "source": [
        "print(encoder_input[0])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[19  3  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpwPCNS7m81N",
        "outputId": "01224411-e558-45b2-dfe7-f77f1e00b553"
      },
      "source": [
        "encoder_input = to_categorical(encoder_input)\n",
        "decoder_input = to_categorical(decoder_input)\n",
        "decoder_target = to_categorical(decoder_target)\n",
        "\n",
        "print('영어 데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 입력데이터의 크기 : ', np.shape(decoder_input))\n",
        "print('프랑스어 출력데이터의 크기 :', np.shape(decoder_target)) #샘플의 수 x 샘플의 길이 x 단어장의 크기"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 입력데이터의 크기 :  (50000, 74, 73)\n",
            "프랑스어 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIrHrMJnm8xi",
        "outputId": "cdf0f052-23b4-4595-d83e-9940f5db79bb"
      },
      "source": [
        "n_of_val = 3000\n",
        "\n",
        "encoder_input_train = encoder_input[:-n_of_val]\n",
        "decoder_input_train = decoder_input[:-n_of_val]\n",
        "decoder_target_train = decoder_target[:-n_of_val]\n",
        "\n",
        "encoder_input_test = encoder_input[-n_of_val:]\n",
        "decoder_input_test = decoder_input[-n_of_val:]\n",
        "decoder_target_test = decoder_target[-n_of_val:]\n",
        "\n",
        "print('영어 학습데이터의 크기 :', np.shape(encoder_input))\n",
        "print('프랑스어 학습 입력데이터의 크기 :', np.shape(decoder_input))\n",
        "print('프랑스어 학습 출력데이터의 크기 :',np.shape(decoder_target))"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "영어 학습데이터의 크기 : (50000, 22, 52)\n",
            "프랑스어 학습 입력데이터의 크기 : (50000, 74, 73)\n",
            "프랑스어 학습 출력데이터의 크기 : (50000, 74, 73)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yWMXxcxm8p1"
      },
      "source": [
        "### 모델 훈련하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE--f6hqnEDP"
      },
      "source": [
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1qCovrfnFg_"
      },
      "source": [
        "# LSTM셀의 마지막 time step의 hidden state와 cell state를 디코더 LSTM의 첫번째 hidden state와 cell state전달해주자\n",
        "\n",
        "encoder_inputs = Input(shape=(None, eng_vocab_size))\n",
        "# 입력 텐서를 생성\n",
        "encoder_lstm = LSTM(units= 256, return_state=True)\n",
        "# hidden state 256인 LSTM을 생성\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
        "# 디코더로 전달할 hidden state, cell state를 리턴. encoder_output은 여기서는 불필요.\n",
        "encoder_states = [state_h, state_c]\n",
        "# hidden state와 cell state를 다음 time step으로 전달하기 위해서 별도로 저장"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOtahNuqnFem"
      },
      "source": [
        "decoder_inputs = Input(shape=(None, fra_vocab_size))\n",
        "# 입력 텐서 생성\n",
        "decoder_lstm = LSTM(units=256, return_sequences= True, return_state=True)\n",
        "# hidden state size 256 디코더 LSTM 생성\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state = encoder_states)\n",
        "# decoder output는 모든 timestep의 hidden state"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYoSqd_hnFcE"
      },
      "source": [
        "decoder_softmax_layer = Dense(fra_vocab_size, activation='softmax')\n",
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhrhOanKnFZr",
        "outputId": "62b8a1fc-0efa-4699-8f83-1f077524b9bc"
      },
      "source": [
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
        "model.summary()"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None, 52)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, 256), (None, 316416      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 lstm_3[0][1]                     \n",
            "                                                                 lstm_3[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 73)     18761       lstm_4[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 673,097\n",
            "Trainable params: 673,097\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBmjyz7lnFW4",
        "outputId": "5c83bcda-469c-46c1-ef34-e50b5543c3d1"
      },
      "source": [
        "model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
        "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), batch_size=128, epochs=30)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "368/368 [==============================] - 11s 22ms/step - loss: 0.9054 - val_loss: 0.7946\n",
            "Epoch 2/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.5527 - val_loss: 0.6447\n",
            "Epoch 3/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.4611 - val_loss: 0.5591\n",
            "Epoch 4/30\n",
            "368/368 [==============================] - 7s 20ms/step - loss: 0.4059 - val_loss: 0.5145\n",
            "Epoch 5/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.3687 - val_loss: 0.4824\n",
            "Epoch 6/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.3421 - val_loss: 0.4454\n",
            "Epoch 7/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.3218 - val_loss: 0.4265\n",
            "Epoch 8/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.3054 - val_loss: 0.4088\n",
            "Epoch 9/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2919 - val_loss: 0.4048\n",
            "Epoch 10/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2804 - val_loss: 0.3948\n",
            "Epoch 11/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2706 - val_loss: 0.3827\n",
            "Epoch 12/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2621 - val_loss: 0.3757\n",
            "Epoch 13/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2543 - val_loss: 0.3717\n",
            "Epoch 14/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2474 - val_loss: 0.3697\n",
            "Epoch 15/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2410 - val_loss: 0.3681\n",
            "Epoch 16/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2352 - val_loss: 0.3634\n",
            "Epoch 17/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2299 - val_loss: 0.3673\n",
            "Epoch 18/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2249 - val_loss: 0.3633\n",
            "Epoch 19/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2203 - val_loss: 0.3646\n",
            "Epoch 20/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2158 - val_loss: 0.3599\n",
            "Epoch 21/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2117 - val_loss: 0.3598\n",
            "Epoch 22/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2077 - val_loss: 0.3630\n",
            "Epoch 23/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2040 - val_loss: 0.3565\n",
            "Epoch 24/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.2004 - val_loss: 0.3641\n",
            "Epoch 25/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1971 - val_loss: 0.3605\n",
            "Epoch 26/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1938 - val_loss: 0.3584\n",
            "Epoch 27/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1906 - val_loss: 0.3660\n",
            "Epoch 28/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1877 - val_loss: 0.3650\n",
            "Epoch 29/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1849 - val_loss: 0.3632\n",
            "Epoch 30/30\n",
            "368/368 [==============================] - 8s 21ms/step - loss: 0.1821 - val_loss: 0.3653\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f3cc01ddc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxw0eC3nFTz"
      },
      "source": [
        "### 모델 테스트\n",
        "\n",
        "훈련시에 학습해야할 타겟문장을 디코더 모델의 입력, 출력 시퀀스로 넣어주고, 디코더 모델이 타겟문장을 한꺼번에 출력하게 할 수 있습니다. 테스트 단계는 불가능!\n",
        "\n",
        "테스트 단계에서 디코더 동작 순서\n",
        "- 인코더에 입력 문장을 넣어 마지막 time step의 hidden, cell state를 얻는다.\n",
        "- 토큰인 \\t를 디코더에 입력한다.\n",
        "- 이전 timestep의 출력층의 예측결과를 현재 timestep의 입력으로 한다.\n",
        "- 3을 반복하다가 토큰인 \\n가 예측되면 이를 중단한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_8HeIvXnTgG",
        "outputId": "7f217221-59e6-429b-9ee2-a0f2f94a0e89"
      },
      "source": [
        "encoder_model = Model(inputs=encoder_inputs, outputs=encoder_states)\n",
        "encoder_model.summary()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None, 52)]        0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                [(None, 256), (None, 256) 316416    \n",
            "=================================================================\n",
            "Total params: 316,416\n",
            "Trainable params: 316,416\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7JtjKujnUdE"
      },
      "source": [
        "decoder_state_input_h = Input(shape=(256,))\n",
        "# 이전 timestep의 hidden state를 저장하는 텐서\n",
        "decoder_state_input_c = Input(shape=(256,))\n",
        "# 이전 timestep의 cell state를 저장하는 텐서\n",
        "decoder_state_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "# 이전 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "\n",
        "# decoder_state_inputs를 현재 time step의 초기상태로 사용\n",
        "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "# 현재 time step의 hidden state와 cell state를 하나의 변수에 저장\n",
        "decoder_states = [state_h, state_c]"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNXXrdLEnUZu",
        "outputId": "a3ae1a4c-95e8-4e36-cea3-bbee3e0227c0"
      },
      "source": [
        "decoder_outputs = decoder_softmax_layer(decoder_outputs)\n",
        "decoder_model= Model(inputs=[decoder_inputs] + decoder_state_inputs, outputs=[decoder_outputs]+decoder_states)\n",
        "decoder_model.summary()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None, 73)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   [(None, None, 256),  337920      input_2[0][0]                    \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 73)     18761       lstm_4[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 356,681\n",
            "Trainable params: 356,681\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuYQpSponUWq"
      },
      "source": [
        "eng2idx = eng_tokenizer.word_index\n",
        "fra2idx = fra_tokenizer.word_index\n",
        "idx2eng = eng_tokenizer.index_word\n",
        "idx2fra = fra_tokenizer.index_word"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKUjjdrhnUTq"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "  # 입력으로부터 인코더의 상태를 얻음\n",
        "  states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "  # <SOS>에 해당하는 원-핫 벡터 생성\n",
        "  target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "  target_seq[0, 0, fra2idx['\\t']] =1\n",
        "\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "\n",
        "  # stop condition이 True가 될떄까지 루프 반복\n",
        "  while not stop_condition:\n",
        "    # 이전 시점의 상태 state_value를 현 시점의 초기 상태로 사용\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq]+ states_value)\n",
        "\n",
        "    # 예측 결과를 문자로 변환\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = idx2fra[sampled_token_index]\n",
        "\n",
        "    # 현재 시점의 예측 문자를 예측 문장에 추가\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # <eos>에 도달하거나 최대 길이를 넘으면 중단\n",
        "    if (sampled_char == '\\n' or\n",
        "        len(decoded_sentence) > max_fra_seq_len):\n",
        "      stop_condition = True\n",
        "\n",
        "    # 현재 시점의 예측 결과를 다음 시점의 입력으로 사용하기 위해 저장\n",
        "    target_seq = np.zeros((1, 1, fra_vocab_size))\n",
        "    target_seq[0, 0, sampled_token_index] =1\n",
        "\n",
        "    # 현재 시점의 상태를 다음 시점의 상태로 사용하기 위해 저장\n",
        "    states_value = [h, c]\n",
        "  return decoded_sentence"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-3bp31bnYgU",
        "outputId": "43d5fd33-6ed3-4b62-9c58-20f1cd891888"
      },
      "source": [
        "import numpy as np\n",
        "for seq_index in [3, 50, 100, 300, 1001]:\n",
        "  # 입력 문장의 인덱스 (자유롭게 바꿔서 테스트 해보세요!)\n",
        "  input_seq = encoder_input[seq_index: seq_index +1]\n",
        "  decoded_sentence = decode_sequence(input_seq)\n",
        "  print(35 * \"-\")\n",
        "  print('입력 문장 :', lines.eng[seq_index])\n",
        "  print('정답 문장 :', lines.fra[seq_index][1:len(lines.fra[seq_index])-1])\n",
        "  # '\\t'와 '\\n'을 빼고 출력\n",
        "  print('번역기가 번역한 문장 :', decoded_sentence[:len(decoded_sentence)-1])\n",
        "  # '\\n'을 빼고 출력"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-----------------------------------\n",
            "입력 문장 : Hi.\n",
            "정답 문장 : Salut !\n",
            "번역기가 번역한 문장 : salut.\n",
            "-----------------------------------\n",
            "입력 문장 : I won!\n",
            "정답 문장 : Je l'ai emporté !\n",
            "번역기가 번역한 문장 : je me demande !\n",
            "-----------------------------------\n",
            "입력 문장 : I fled.\n",
            "정답 문장 : J'ai fui.\n",
            "번역기가 번역한 문장 : j'ai plus chante.\n",
            "-----------------------------------\n",
            "입력 문장 : Hug Tom.\n",
            "정답 문장 : Fais un câlin à Tom.\n",
            "번역기가 번역한 문장 : dégage !\n",
            "-----------------------------------\n",
            "입력 문장 : I give in.\n",
            "정답 문장 : Je donne ma langue au chat.\n",
            "번역기가 번역한 문장 : je l'ai dit.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiW6R6emnYcR"
      },
      "source": [
        ""
      ],
      "execution_count": 134,
      "outputs": []
    }
  ]
}